{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPI Data Prepration<a id='top'></a>\n",
    "**Sections:**<br>\n",
    "[0) Description](#0)<br>\n",
    "[1) Importing Modules and Packages](#1)<br>\n",
    "[2) Configuration](#2)<br>\n",
    "[3) Loading Gene Ontology](#3)<br>\n",
    "[4) Loading Genes and Annotations](#4)<br>\n",
    "[5) Loading PPI data](#5)<br>\n",
    "[6) Generating Negartive PPI data](#6)<br>\n",
    "[7) Saving the results](#7)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description<a id='0'></a>\n",
    "\n",
    "**Aim:** This jupyter notebook results in PPI data of species of interest (e.g., _human_ or *yeast*) with which the deepSimDEF networks would be trained and evaluatied.\n",
    "\n",
    "---\n",
    "**Output file format:** (space separated)<br>\n",
    "_protein1_ _protein2_ _interaction_label_ <br>\n",
    "CD44 ARHGEF1 1<br>\n",
    "POLR2G CTDP1 1<br>\n",
    "...<br>\n",
    "OR5L2 SLC7A11 0<br>\n",
    "SCNM1 CEP120 0<br>\n",
    "...<br>\n",
    "\n",
    "---\n",
    "Files needed for this preprocessing are:\n",
    "\n",
    " * **Gene ontology:** ['go.obo' file](http://current.geneontology.org/ontology/go.obo)<br><br>\n",
    " \n",
    " * **Association files:** [gene association files ingested from GO Consortium members](http://current.geneontology.org/products/pages/downloads.html)\n",
    "  * **Human** - [Gene Association file (Homo sapiens)](http://geneontology.org/gene-associations/goa_human.gaf.gz)\n",
    "  * **Yeast** - [Gene Association file (Saccharomyces cerevisiae)](http://current.geneontology.org/annotations/sgd.gaf.gz)<br><br>\n",
    "  \n",
    " * **PPI data:** [String website](https://string-db.org/cgi/input.pl?sessionId=a5gYvToqoD08&input_page_show_search=off) [Examples](https://string-db.org/cgi/input.pl?sessionId=Yxc5T5teWAUN&input_page_active_form=examples)<br>\n",
    "         \n",
    "     * **Human** - [String website for PPI data (Homo sapiens)](https://string-db.org/cgi/download.pl?sessionId=rEreY0WA5fL8&species_text=Homo+sapiens)\n",
    "         * Protein links full: [Protein Protein Interaction file - full](https://stringdb-static.org/download/protein.links.full.v11.0/9606.protein.links.full.v11.0.txt.gz)\n",
    "         * Protein info: [Protein Protein Interaction file - information](https://stringdb-static.org/download/protein.info.v11.0/9606.protein.info.v11.0.txt.gz)\n",
    "         * Protein actions: [Protein Protein Interaction file - action](https://stringdb-static.org/download/protein.actions.v11.0/9606.protein.actions.v11.0.txt.gz)<br>\n",
    "         \n",
    "     * **Yeast** - [String website for PPI data (Saccharomyces cerevisiae)](https://string-db.org/cgi/download.pl?sessionId=rEreY0WA5fL8&species_text=Saccharomyces+cerevisiae)\n",
    "         * Protein links full: [Protein Protein Interaction file - full](https://stringdb-static.org/download/protein.links.full.v11.0/4932.protein.links.full.v11.0.txt.gz)\n",
    "         * Protein info: [Protein Protein Interaction file - information](https://stringdb-static.org/download/protein.info.v11.0/4932.protein.info.v11.0.txt.gz)\n",
    "         * Protein actions: [Protein Protein Interaction file - action](https://stringdb-static.org/download/protein.actions.v11.0/4932.protein.actions.v11.0.txt.gz)<br>\n",
    "         * Extra source: ['yeastgenome.org' interaction data](http://downloads.yeastgenome.org/pub/yeast/literature_curation/interaction_data.tab)\n",
    "\n",
    "---\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import<a id='1'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import easydict\n",
    "import linecache\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration<a id='2'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = 'yeast' # species of interest to load of and save the resut for\n",
    "confidence_threshold = {'human': 850, 'yeast': 650}\n",
    "\n",
    "if species=='human':\n",
    "    association_file_name = 'goa_human.gaf.gz' # human\n",
    "    association_file_url = 'http://geneontology.org/gene-associations/goa_human.gaf.gz'\n",
    "    interactions_full_file = '9606.protein.links.full.v11.0.txt.gz'\n",
    "    interactions_full_url = 'https://stringdb-static.org/download/protein.links.full.v11.0/9606.protein.links.full.v11.0.txt.gz'\n",
    "    interactions_action_file = '9606.protein.actions.v11.0.txt.gz'\n",
    "    interactions_action_url = 'https://stringdb-static.org/download/protein.actions.v11.0/9606.protein.actions.v11.0.txt.gz'\n",
    "    interactions_info_file = '9606.protein.info.v11.0.txt.gz'\n",
    "    interactions_info_url = 'https://stringdb-static.org/download/protein.info.v11.0/9606.protein.info.v11.0.txt.gz'\n",
    "elif species=='yeast':\n",
    "    association_file_name = 'sgd.gaf.gz' # yeast\n",
    "    association_file_url = 'http://current.geneontology.org/annotations/sgd.gaf.gz'\n",
    "    interactions_full_file = '4932.protein.links.full.v11.0.txt.gz'\n",
    "    interactions_full_url = 'https://stringdb-static.org/download/protein.links.full.v11.0/4932.protein.links.full.v11.0.txt.gz'\n",
    "    interactions_action_file = '4932.protein.actions.v11.0.txt.gz'\n",
    "    interactions_action_url = 'https://stringdb-static.org/download/protein.actions.v11.0/4932.protein.actions.v11.0.txt.gz'\n",
    "    interactions_info_file = '4932.protein.info.v11.0.txt.gz'\n",
    "    interactions_info_url = 'https://stringdb-static.org/download/protein.info.v11.0/4932.protein.info.v11.0.txt.gz'\n",
    "    interactions_extra_file = 'interaction_data.tab'\n",
    "    interactions_extra_url = 'http://sgd-archive.yeastgenome.org/?prefix=pub/yeast/literature_curation/interaction_data.tab'\n",
    "    \n",
    "args = easydict.EasyDict({\n",
    "    \"go_dir\": 'gene_ontology/raw/',     # directory to the Gene Ontology 'go.obo' file\n",
    "    \"association_file_dir\": 'species/{}/association_file/raw'.format(species), # directory to the human association file\n",
    "    \"interaction_files_dir\": 'species/{}/ppi/raw'.format(species), # directory to the human association file\n",
    "    \"ppi_raw_dir\": 'species/{}/ppi/raw'.format(species),                       # directory to the raw ppi data\n",
    "    \"result_ppi_dir\": 'species/{}/ppi/processed'.format(species),              # directory in which the results would be saved\n",
    "    \"combined_score_threshold\": confidence_threshold[species],   # the score to filter out low confident interactions (only those above the score are kept)\n",
    "    \"download_gene_ontology\": True,     # download the latest version of gene ontology into the specified directory above\n",
    "    \"download_association_file\": True,  # download association file of the specieis of interest into the specified directory above\n",
    "    \"download_interaction_files\": True,  # download interaction files of the specieis of interest into the specified directory above\n",
    "    \"extra_ppi_source\": False,           # includig extra source of positive PPI information to generate better negative PPIs\n",
    "    \"seed\": 2021                         # seed to make sure the random negative samples are reproducable\n",
    "})\n",
    "\n",
    "os.makedirs(args.result_ppi_dir, exist_ok=True)  # create 'result_ppi_dir' folder (if it does not exist already)\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "subontology_map = {\"C\":\"CC\", \"P\":\"BP\", \"F\":\"MF\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Gene Ontology<a id='3'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.download_gene_ontology:\n",
    "    os.makedirs(args.go_dir, exist_ok=True)  # create 'data_loc' folder (if it does not exist already)\n",
    "    print(\"Downloading the latest version of Gene Ontology into '{}'...\".format(args.go_dir))\n",
    "    url = 'http://current.geneontology.org/ontology/go.obo'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open('{}/go.obo'.format(args.go_dir), 'wb').write(r.content)\n",
    "\n",
    "print(\"Gene Ontology {}\".format(linecache.getline('{}/go.obo'.format(args.go_dir), 2))) # Now: releases/2020-03-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reading Gene Ontology to extract Terms and their Descriptive Names\"\"\"\n",
    "with open(\"{}/go.obo\".format(args.go_dir)) as f:\n",
    "    content = f.readlines()\n",
    "content = \"\".join([x for x in content])\n",
    "content = content.split(\"[Typedef]\")[0].split(\"[Term]\")\n",
    "print(\"Information of the last GO term in the file:\\n~~~~~~~~~~~~~~~~~~~~~~~~~{}\".format(content[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Going through every GO term and extract information needed ('id', 'alt_id', 'namespace', and 'is_obsolete')\"\"\"\n",
    "go_term_dict = {}\n",
    "for c in content:\n",
    "    go_id = ''\n",
    "    for l in c.split(\"\\n\"):\n",
    "        # id\n",
    "        if \"id: GO:\" in l[0:len(\"id: GO:\")]:\n",
    "            go_id = l.split(\"id: \")[1]\n",
    "            go_term_dict[go_id] = {}\n",
    "        # alt_id\n",
    "        if \"alt_id:\" in l[0:len(\"alt_id\")+1]:\n",
    "            go_term_dict[go_id].setdefault(\"alt_id\", []).append(l.split(\"alt_id: \")[1])\n",
    "        # namespace\n",
    "        if \"namespace:\" in l[0:len(\"namespace\")+1]:\n",
    "            go_term_dict[go_id][\"namespace\"] = l.split(\"namespace: \")[1]\n",
    "        # is_obsolete\n",
    "        if \"is_obsolete:\" in l[0:len(\"is_obsolete\")+1]:\n",
    "            go_term_dict[go_id][\"is_obsolete\"] = l.split(\"is_obsolete: \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"printing how the key:values are organized for every GO term\"\"\"\n",
    "for i in range(15):\n",
    "    print(list(go_term_dict)[i], end=\": \")\n",
    "    pp.pprint(go_term_dict[list(go_term_dict)[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"grouping GO terms based on the sub-ontologies they belong to\"\"\"\n",
    "subontology_go_term_dict = {}\n",
    "for go_id in go_term_dict:\n",
    "    if not go_term_dict[go_id].get('is_obsolete', False): # or => if 'is_obsolete' not in go_term_dict[go_id]:\n",
    "        subontology_go_term_dict.setdefault(go_term_dict[go_id]['namespace'].split('_')[1][0].upper(), []).append(go_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"including 'alt_id' into the sub-ontology's groups of GO terms\"\"\"\n",
    "for go_id in go_term_dict:\n",
    "    if go_term_dict[go_id].get('alt_id', False): # or => if 'alt_id' in go_term_dict[go_id]:\n",
    "        for alt_id in go_term_dict[go_id].get('alt_id'):\n",
    "            subontology_go_term_dict[go_term_dict[go_id]['namespace'].split('_')[1][0].upper()].append(alt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"printing how the key:values are organized for different sub-ontologies\"\"\"\n",
    "for subontology in subontology_go_term_dict:\n",
    "    print(\"{} ({}):: {} <= {} GO term (with 'alt_id') => {}\".format(\n",
    "        subontology, \n",
    "        subontology_map[subontology], \n",
    "        \" \".join(subontology_go_term_dict[subontology][:3]), \n",
    "        len(subontology_go_term_dict[subontology]), \n",
    "        \" \".join(subontology_go_term_dict[subontology][-3:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Genes and Annotations<a id='4'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.download_association_file:\n",
    "    os.makedirs(args.association_file_dir, exist_ok=True)  # create 'data_loc' folder (if it does not exist already)\n",
    "    print(\"Downloading the latest version of association file into '{}'...\".format(args.association_file_dir))\n",
    "    r = requests.get(association_file_url, allow_redirects=True)\n",
    "    open('{}/{}'.format(args.association_file_dir, association_file_name), 'wb').write(r.content)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"{}/{}\".format(args.association_file_dir, association_file_name), sep='\\t', comment=\"!\", skip_blank_lines=True, header=None, dtype=str)\n",
    "df = df.iloc[:,[1, 2, 3, 4, 6, 8]]\n",
    "if len(df[df[3].isnull()])==0:\n",
    "    df = df[~df[3].str.contains(\"NOT\")]\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "else:\n",
    "    df = df[df[3].isnull()]\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "df = df.drop(df.columns[2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"keeping track of the gene ids and their mappings\"\"\"\n",
    "protein_gene_id_map = {}\n",
    "for gene_id, protein_id in zip(df[1], df[2]):\n",
    "    protein_gene_id_map[protein_id] = gene_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### removing 'ND' and 'IEA' annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[6]!='ND') & (df[6]!='IEA')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"protein dictionary to keep track of annotations for proteins (from each sub-ontology)\"\"\"\n",
    "proteins_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    gene = row[2]\n",
    "    go_term_id = row[4]\n",
    "    subontology = row[8]\n",
    "    if go_term_id in subontology_go_term_dict[subontology]:\n",
    "        proteins_dict.setdefault(gene, dict()).setdefault(subontology, set()).add(go_term_id)\n",
    "        \n",
    "\"\"\"printing how the key:values are organized for every gene/protein\"\"\"\n",
    "for i in range(5):\n",
    "    print(list(proteins_dict)[i], end=\": \")\n",
    "    pp.pprint(proteins_dict[list(proteins_dict)[i]])\n",
    "print(\"\\nTotal number of genes/proteins annotated:\", len(proteins_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking into account only fully annotated genes/proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"keeping track of fully annotated genes/proteins\"\"\"\n",
    "fully_annotated_proteins_wo_iea = []\n",
    "for protein in proteins_dict:\n",
    "    if len(proteins_dict[protein]) == 3:\n",
    "        fully_annotated_proteins_wo_iea.append(protein)\n",
    "print(\"Out of {} proteins {} are (experimentally or manually) annotated by all three sub-ontologies.\".format(len(proteins_dict), len(fully_annotated_proteins_wo_iea)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading PPI data<a id='5'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.download_interaction_files:\n",
    "    os.makedirs(args.interaction_files_dir, exist_ok=True)  # create 'data_loc' folder (if it does not exist already)\n",
    "    print(\"Downloading the latest version of interaction files into '{}'...\".format(args.interaction_files_dir))\n",
    "    \n",
    "    r = requests.get(interactions_full_url, allow_redirects=True)\n",
    "    open('{}/{}'.format(args.interaction_files_dir, interactions_full_file), 'wb').write(r.content)\n",
    "    \n",
    "    r = requests.get(interactions_action_url, allow_redirects=True)\n",
    "    open('{}/{}'.format(args.interaction_files_dir, interactions_action_file), 'wb').write(r.content)\n",
    "    \n",
    "    r = requests.get(interactions_info_url, allow_redirects=True)\n",
    "    open('{}/{}'.format(args.interaction_files_dir, interactions_info_file), 'wb').write(r.content)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.extra_ppi_source:\n",
    "    os.makedirs(args.interaction_files_dir, exist_ok=True)  # create 'data_loc' folder (if it does not exist already)\n",
    "    print(\"Downloading the latest version of interaction files into '{}'...\".format(args.interaction_files_dir))\n",
    "    \n",
    "    r = requests.get(interactions_extra_url, allow_redirects=True)\n",
    "    open('{}/{}'.format(args.interaction_files_dir, interactions_extra_file), 'wb').write(r.content)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading species PPI info file to map names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppi_info = pd.read_csv(\"{}/{}\".format(args.ppi_raw_dir, interactions_info_file), sep='\\t')\n",
    "df_ppi_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map_dict = {}\n",
    "for protein_external_id, preferred_name in zip(df_ppi_info['protein_external_id'] , df_ppi_info['preferred_name']):\n",
    "    id_map_dict[protein_external_id] = preferred_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading species PPI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppi = pd.read_csv(\"{}/{}\".format(args.ppi_raw_dir, interactions_full_file), sep=' ')\n",
    "df_ppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"we need all positive interactions for the generation of negative interactions\"\"\"\n",
    "all_positive_interactions = set()\n",
    "for protein1, protein2 in zip(df_ppi['protein1'] , df_ppi['protein2']):\n",
    "    all_positive_interactions.add(\"{} {}\".format(id_map_dict[protein1], id_map_dict[protein2]))\n",
    "    all_positive_interactions.add(\"{} {}\".format(id_map_dict[protein2], id_map_dict[protein1]))\n",
    "\n",
    "\"\"\"including other sources into consideration to create better negative PPIs later\"\"\"\n",
    "if args.extra_ppi_source:\n",
    "    if species=='yeast':\n",
    "        extra_file = 'interaction_data.tab'\n",
    "        print(\"Extra source of PPI for {} ('{}' file).\".format(species, extra_file))\n",
    "        df_ppi_another = pd.read_csv(\"{}/{}\".format(args.ppi_raw_dir, extra_file), sep='\\t', header=None)\n",
    "        for index, row in df_ppi_another.iterrows():\n",
    "            all_positive_interactions.add(\"{} {}\".format(row[1], row[3]))\n",
    "            all_positive_interactions.add(\"{} {}\".format(row[3], row[1]))\n",
    "    elif species=='human':\n",
    "        print(\"No extra source of PPI for {}.\".format(species))\n",
    "\n",
    "print(\"The total number of all positive interactions are:\", len(all_positive_interactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimentally Supported Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"keeping only those annotations which are supported experimentally and are with high confidence score\"\"\"\n",
    "df_ppi = df_ppi[(df_ppi['experiments']!=0) & (args.combined_score_threshold<df_ppi['combined_score'])][['protein1', 'protein2', 'experiments', 'combined_score']]\n",
    "df_ppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentally_positive_interactions = set()\n",
    "for protein1, protein2 in zip(df_ppi['protein1'] , df_ppi['protein2']):\n",
    "    experimentally_positive_interactions.add(\"{} {}\".format(id_map_dict[protein1], id_map_dict[protein2]))\n",
    "    experimentally_positive_interactions.add(\"{} {}\".format(id_map_dict[protein2], id_map_dict[protein1]))\n",
    "    \n",
    "print(\"Number of experimentally positive interactions (with confidense score of {}): {}\".format(args.combined_score_threshold, len(experimentally_positive_interactions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physical (i.e. binding) vs Functional Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"would be interested only in physical interactions (typically binding)\"\"\"\n",
    "\"\"\"for more information refer to: 'http://version10.string-db.org/help/faq/#how-do-i-extract-purely-experimental-data'\"\"\" \n",
    "df_ppi_physical = pd.read_csv(\"{}/{}\".format(args.ppi_raw_dir, interactions_action_file), sep='\\t')\n",
    "df_ppi_physical = df_ppi_physical[df_ppi_physical['mode']=='binding'][['item_id_a', 'item_id_b', 'mode']]\n",
    "df_ppi_physical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_interactions = set()\n",
    "for protein1, protein2 in zip(df_ppi_physical['item_id_a'] , df_ppi_physical['item_id_b']):\n",
    "    physical_interactions.add(\"{} {}\".format(id_map_dict[protein1], id_map_dict[protein2]))\n",
    "    physical_interactions.add(\"{} {}\".format(id_map_dict[protein2], id_map_dict[protein1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now consider only experimental & physical interactions for which we have full annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentally_positive_interactions = experimentally_positive_interactions.intersection(physical_interactions)\n",
    "print(\"Total number of experimentally positive physical interactions:\", len(experimentally_positive_interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for proper experiment, we only consider proteins which all fully annotated\"\"\"\n",
    "fully_annotated_positive_interactions = set()\n",
    "for interaction in sorted(experimentally_positive_interactions):\n",
    "    p1, p2 = interaction.split()\n",
    "    if (p1 in fully_annotated_proteins_wo_iea) and (p2 in fully_annotated_proteins_wo_iea):\n",
    "        if p1==p2:\n",
    "            fully_annotated_positive_interactions.add(\"{} {}\".format(p1, p2))\n",
    "        elif \"{} {}\".format(p2, p1) not in fully_annotated_positive_interactions:\n",
    "            fully_annotated_positive_interactions.add(\"{} {}\".format(p1, p2))\n",
    "            \n",
    "print(\"Out of {} gene pairs, {} are fully annotated by all three sub-ontologies.\".format(len(experimentally_positive_interactions), len(fully_annotated_positive_interactions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Negative PPI data<a id='6'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"we generate negative interactions by random sampling while making sure the are not positive of any form\"\"\"\n",
    "fully_annotated_negative_interactions = set()\n",
    "count = 0\n",
    "while count != len(fully_annotated_positive_interactions):\n",
    "    protein1, protein2 = np.random.choice(fully_annotated_proteins_wo_iea, 2)\n",
    "    if \"{} {}\".format(protein1, protein2) not in all_positive_interactions:\n",
    "        if \"{} {}\".format(protein1, protein2) not in fully_annotated_negative_interactions:\n",
    "\n",
    "            fully_annotated_negative_interactions.add(\"{} {}\".format(protein1, protein2))\n",
    "            count += 1\n",
    "\n",
    "print(\"Total number of positive interactions ({}): {}\".format(species, len(fully_annotated_negative_interactions)))\n",
    "print(\"Total number of negative interactions ({}): {}\".format(species, len(fully_annotated_positive_interactions)))\n",
    "print(\"Total size of the PPI dataset is: {}\".format(len(fully_annotated_negative_interactions)*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the results<a id='7'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{args.result_ppi_dir}/{species}_protein_protein_interaction.tsv', 'w') as fw:\n",
    "    fw.write(\"Protein_1\\tProtein_2\\tInteraction_label\\n\")\n",
    "    for positive_interaction in sorted(fully_annotated_positive_interactions):\n",
    "        positive_interaction = positive_interaction.replace(' ', '\\t')\n",
    "        fw.write(f\"{positive_interaction}\\t1\\n\")\n",
    "    for negative_interaction in sorted(fully_annotated_negative_interactions):\n",
    "        negative_interaction = negative_interaction.replace(' ', '\\t')\n",
    "        fw.write(f\"{negative_interaction}\\t0\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{args.result_ppi_dir}/{species}_protein_protein_interaction.tsv\", sep=\"\\t\", dtype=str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_genes = set(list(df.Protein_1) + list(df.Protein_2))\n",
    "print(f\"Number of {species} genes:\", len(ppi_genes))\n",
    "with open(f'{args.result_ppi_dir}/{species}_protein_protein_interaction_genes.tsv'.format(), 'w') as fw:\n",
    "    for gene in sorted(ppi_genes):\n",
    "        fw.write(f\"{gene}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)<br>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepSimDEF_env]",
   "language": "python",
   "name": "conda-env-deepSimDEF_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

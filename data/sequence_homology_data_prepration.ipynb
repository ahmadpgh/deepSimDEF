{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Homology Data Prepration<a id='top'></a>\n",
    "**Sections:**<br>\n",
    "[0) Description](#0)<br>\n",
    "[1) BLAST](#1)<br>\n",
    "[2) Importing Modules and Packages](#2)<br>\n",
    "[3) Configuration](#3)<br>\n",
    "[4) Loading Gene Ontology](#4)<br>\n",
    "[5) Loading Genes and Annotations](#5)<br>\n",
    "[6) Loading Sequence Homology data](#6)<br>\n",
    "[7) Computing log-reciprocal BLAST score (LRBS) and relative reciprocal BLAST score (RRBS)](#7)<br>\n",
    "[8) Saving the results](#8)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description<a id='0'></a>\n",
    "\n",
    "**Aim:** This jupyter notebook results in **protein sequence similarity** data of species of interest (e.g., _human_ or *yeast*) with which the deepSimDEF networks would be trained and evaluatied. The similarity metrics employed are LRBS and RRBS.\n",
    "\n",
    "---\n",
    "**Output file format:** (space separated)<br>\n",
    "_Protein_1_ _Protein_2_ _LRBS_ _RRBS_ <br>\n",
    "A6NMZ5 A6NND4 2.095169 0.195754<br>\n",
    "O94885 Q96HU1 1.606381 0.019799<br>\n",
    "P29320 Q9Y572 1.983626 0.061849<br>\n",
    "Q8IY84 Q8TEA7 1.694605 0.036144<br>\n",
    "...<br>\n",
    "\n",
    "---\n",
    "Files needed for this preprocessing are:\n",
    "\n",
    " * **Gene ontology:** ['go.obo' file](http://current.geneontology.org/ontology/go.obo)<br><br>\n",
    " \n",
    " * **Association files:** [gene association files ingested from GO Consortium members](http://current.geneontology.org/products/pages/downloads.html)\n",
    "  * **Human** - [Gene Association file (Homo sapiens)](http://geneontology.org/gene-associations/goa_human.gaf.gz)\n",
    "  * **Yeast** - [Gene Association file (Saccharomyces cerevisiae)](http://current.geneontology.org/annotations/sgd.gaf.gz)<br><br>\n",
    "  \n",
    " * **FASTA data:** [UniProt website (Proteomes)](https://www.uniprot.org/proteomes/)<br>\n",
    "         \n",
    "     * **Human** - [Proteomes - Homo sapiens (Human)](https://www.uniprot.org/proteomes/UP000005640)\n",
    "         * Protein sequences: [one protein sequence per gene (FASTA)](ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/reference_proteomes/Eukaryota/UP000005640_9606.fasta.gz)\n",
    "         \n",
    "     * **Yeast** - [Proteomes - Saccharomyces cerevisiae (Baker's yeast)](https://www.uniprot.org/proteomes/UP000002311)\n",
    "         * Protein sequences: [one protein sequence per gene (FASTA)](ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/reference_proteomes/Eukaryota/UP000002311_559292.fasta.gz)\n",
    "         \n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLAST<a id='1'></a>\n",
    "To get the sequence similarity from BLAST I used Compute Canada server on which blast was installed in advance; if you do not use that servers, make sure you have BLAST installed on you system . The results from blast (<code>blastp</code> for protein similarity) will be what we process here. The steps to get the <code>blastp</code> result are as follow.<br>\n",
    "\n",
    "Keep in mind the we work with *E-value* of $0.1$ (by setting <code>-evalue 10</code>). For more information refer to [What is the Expect (E) value?](https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=FAQ#expect).\n",
    "\n",
    "---\n",
    "#### load blast module\n",
    "<font size=\"2\">\n",
    "For Compute Canada servers you need to load these (the <code>nixpkgs</code> and <code>gcc</code> are requisite for <code>blast+</code>):<br>\n",
    "<code>module load nixpkgs/16.09 gcc/7.3.0 blast+/2.10.0</code><br>\n",
    "Otherwise install BLAST from this link: [Basic Local Alignment Search Tool](https://blast.ncbi.nlm.nih.gov/Blast.cgi)\n",
    "</font>\n",
    "\n",
    "---\n",
    "#### human sequence (FASTA)<br>\n",
    "<font size=\"2\">\n",
    "1) Download the protein sequences (human) in zipped FASTA format (then unzip the file):<br>\n",
    "<code>wget https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/reference_proteomes/Eukaryota/UP000005640/UP000005640_9606.fasta.gz</code><br>\n",
    "<code>gunzip UP000005640_9606.fasta.gz</code><br>\n",
    "\n",
    "2) Build the database as an indexting task needed for an efficient search (<code>makeblastdb</code> is part of the BLAST):<br>\n",
    "<code>makeblastdb -in UP000005640_9606.fasta -dbtype prot</code><br>\n",
    "\n",
    "3) Apply <code>blastp</code> by: (<code>-outfmt 6</code> means output be saved in tabular format)<br>\n",
    "Notice: On Compute Canada servers, for faster computation, use <code>sbatch</code> command with proper settings  (Set <code>--cpus-per-task=16</code> and <code>--mem-per-cpu=512M</code>)<br>\n",
    "<code>blastp -query UP000005640_9606.fasta -db UP000005640_9606.fasta -evalue 10 -outfmt 6 -num_threads 16 -out human_vs_human_blastp_results.tab</code><br>\n",
    "\n",
    "4) Zip the result for a faster transfer/loading: (the result of this step, which is **human_vs_human_blastp_results.tab.gz**, is going to be processed in this notebook) <br>\n",
    "<code>gzip human_vs_human_blastp_results.tab</code><br>\n",
    "\n",
    "---\n",
    "#### yeast sequence (FASTA)<br>\n",
    "<font size=\"2\">\n",
    "1) Download the protein sequences (yeas) in zipped FASTA format (then unzip the file):<br>\n",
    "<code>wget https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/reference_proteomes/Eukaryota/UP000002311/UP000002311_559292.fasta.gz</code><br>\n",
    "<code>gunzip UP000002311_559292.fasta.gz</code><br>\n",
    "\n",
    "2) Build the database as an indexting task needed for an efficient search (<code>makeblastdb</code> is part of the BLAST):<br>\n",
    "<code>makeblastdb -in UP000002311_559292.fasta -dbtype prot</code><br>\n",
    "\n",
    "3) Apply <code>blastp</code> by: (<code>-outfmt 6</code> means output be saved in tabular format)<br>\n",
    "Notice: On Compute Canada servers, for faster computation, use <code>sbatch</code> command with proper settings  (Set <code>--cpus-per-task=16</code> and <code>--mem-per-cpu=512M</code>)<br>\n",
    "<code>blastp -query UP000002311_559292.fasta -db UP000002311_559292.fasta -evalue 10 -outfmt 6 -num_threads 16 -out yeast_vs_yeast_blastp_results.tab</code><br>\n",
    "\n",
    "4) Zip the results for a faster transfer/loading: (the result of this step, which is **yeast_vs_yeast_blastp_results.tab.gz**, is going to be processed in this notebook)<br>\n",
    "<code>gzip yeast_vs_yeast_blastp_results.tab</code><br>\n",
    "\n",
    "</font>\n",
    "\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import<a id='2'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import easydict\n",
    "import linecache\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration<a id='3'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = 'yeast' # species of interest to load of and save the resut for\n",
    "\n",
    "if species=='human':\n",
    "    association_file_name = 'goa_human.gaf.gz' # human\n",
    "    blastp_file = 'human_vs_human_blastp_results.tab.gz'\n",
    "    association_file_url = 'http://geneontology.org/gene-associations/goa_human.gaf.gz'\n",
    "elif species=='yeast':\n",
    "    association_file_name = 'sgd.gaf.gz' # yeast\n",
    "    blastp_file = 'yeast_vs_yeast_blastp_results.tab.gz'\n",
    "    association_file_url = 'http://current.geneontology.org/annotations/sgd.gaf.gz'\n",
    "    \n",
    "args = easydict.EasyDict({\n",
    "    \"go_dir\": 'gene_ontology/raw/',    # directory to the Gene Ontology 'go.obo' file\n",
    "    \"association_file_dir\": 'species/{}/association_file/raw'.format(species), # directory to the human association file\n",
    "    \"sequence_homology_raw_dir\": 'species/{}/sequence_homology/raw'.format(species),   # directory to the raw sequence_homology data computed from BLAST\n",
    "    \"result_sequence_homology_dir\": 'species/{}/sequence_homology/processed'.format(species), # directory in which the results would be saved\n",
    "    #\"epectation_value\": 0.1,           # the score to filter out low confident interactions (only those above the score are kept)\n",
    "    \"download_gene_ontology\": True,    # download the latest version of gene ontology into the specified directory above\n",
    "    \"download_association_file\": True  # download association file of the specieis of interest into the specified directory above\n",
    "})\n",
    "\n",
    "os.makedirs(args.result_sequence_homology_dir, exist_ok=True)  # create 'result_sequence_homology_dir' folder (if it does not exist already)\n",
    "\n",
    "subontology_map = {\"C\":\"CC\", \"P\":\"BP\", \"F\":\"MF\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(f\"{args.sequence_homology_raw_dir}/{blastp_file}\") is True, f\"\\nYou need to prepare the blastp file first based on the guideline provided above! \\nPut the {blastp_file} file in '{args.sequence_homology_raw_dir}/' directory.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Gene Ontology<a id='4'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.download_gene_ontology:\n",
    "    os.makedirs(args.go_dir, exist_ok=True)  # create 'data_loc' folder (if it does not exist already)\n",
    "    print(\"Downloading the latest version of Gene Ontology into '{}'...\".format(args.go_dir))\n",
    "    url = 'http://current.geneontology.org/ontology/go.obo'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open('{}/go.obo'.format(args.go_dir), 'wb').write(r.content)\n",
    "\n",
    "print(\"Gene Ontology {}\".format(linecache.getline('{}/go.obo'.format(args.go_dir), 2))) # Now: releases/2020-03-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reading Gene Ontology to extract Terms and their Descriptive Names\"\"\"\n",
    "with open(\"{}/go.obo\".format(args.go_dir)) as f:\n",
    "    content = f.readlines()\n",
    "content = \"\".join([x for x in content])\n",
    "content = content.split(\"[Typedef]\")[0].split(\"[Term]\")\n",
    "print(\"Information of the last GO term in the file:\\n~~~~~~~~~~~~~~~~~~~~~~~~~{}\".format(content[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Going through every GO term and extract information needed ('id', 'alt_id', 'namespace', and 'is_obsolete')\"\"\"\n",
    "go_term_dict = {}\n",
    "for c in content:\n",
    "    go_id = ''\n",
    "    for l in c.split(\"\\n\"):\n",
    "        # id\n",
    "        if \"id: GO:\" in l[0:len(\"id: GO:\")]:\n",
    "            go_id = l.split(\"id: \")[1]\n",
    "            go_term_dict[go_id] = {}\n",
    "        # alt_id\n",
    "        if \"alt_id:\" in l[0:len(\"alt_id\")+1]:\n",
    "            go_term_dict[go_id].setdefault(\"alt_id\", []).append(l.split(\"alt_id: \")[1])\n",
    "        # namespace\n",
    "        if \"namespace:\" in l[0:len(\"namespace\")+1]:\n",
    "            go_term_dict[go_id][\"namespace\"] = l.split(\"namespace: \")[1]\n",
    "        # is_obsolete\n",
    "        if \"is_obsolete:\" in l[0:len(\"is_obsolete\")+1]:\n",
    "            go_term_dict[go_id][\"is_obsolete\"] = l.split(\"is_obsolete: \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"printing how the key:values are organized for every GO term\"\"\"\n",
    "for i in range(15):\n",
    "    print(list(go_term_dict)[i], end=\": \")\n",
    "    pp.pprint(go_term_dict[list(go_term_dict)[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"grouping GO terms based on the sub-ontologies they belong to\"\"\"\n",
    "subontology_go_term_dict = {}\n",
    "for go_id in go_term_dict:\n",
    "    if not go_term_dict[go_id].get('is_obsolete', False): # or => if 'is_obsolete' not in go_term_dict[go_id]:\n",
    "        subontology_go_term_dict.setdefault(go_term_dict[go_id]['namespace'].split('_')[1][0].upper(), []).append(go_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"including 'alt_id' into the sub-ontology's groups of GO terms\"\"\"\n",
    "for go_id in go_term_dict:\n",
    "    if go_term_dict[go_id].get('alt_id', False): # or => if 'alt_id' in go_term_dict[go_id]:\n",
    "        for alt_id in go_term_dict[go_id].get('alt_id'):\n",
    "            subontology_go_term_dict[go_term_dict[go_id]['namespace'].split('_')[1][0].upper()].append(alt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"printing how the key:values are organized for different sub-ontologies\"\"\"\n",
    "for subontology in subontology_go_term_dict:\n",
    "    print(\"{} ({}):: {} <= {} GO term (with 'alt_id') => {}\".format(\n",
    "        subontology, \n",
    "        subontology_map[subontology], \n",
    "        \" \".join(subontology_go_term_dict[subontology][:3]), \n",
    "        len(subontology_go_term_dict[subontology]), \n",
    "        \" \".join(subontology_go_term_dict[subontology][-3:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Genes and Annotations<a id='5'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.download_association_file:\n",
    "    os.makedirs(args.association_file_dir, exist_ok=True)  # create 'data_loc' folder (if it does not exist already)\n",
    "    print(\"Downloading the latest version of association file into '{}'...\".format(args.association_file_dir))\n",
    "    r = requests.get(association_file_url, allow_redirects=True)\n",
    "    open('{}/{}'.format(args.association_file_dir, association_file_name), 'wb').write(r.content)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"{}/{}\".format(args.association_file_dir, association_file_name), sep='\\t', comment=\"!\", skip_blank_lines=True, header=None, dtype=str)\n",
    "df = df.iloc[:,[1, 2, 3, 4, 6, 8]]\n",
    "if len(df[df[3].isnull()])==0:\n",
    "    df = df[~df[3].str.contains(\"NOT\")]\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "else:\n",
    "    df = df[df[3].isnull()]\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "df = df.drop(df.columns[2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"keeping track of the gene ids and their mappings\"\"\"\n",
    "protein_gene_id_map = {}\n",
    "for gene_id, protein_id in zip(df[1], df[2]):\n",
    "    protein_gene_id_map[protein_id] = gene_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### removing 'ND' and 'IEA' annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[6]!='ND') & (df[6]!='IEA')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"protein dictionary to keep track of annotations for proteins (from each sub-ontology)\"\"\"\n",
    "proteins_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    gene = row[1]\n",
    "    go_term_id = row[4]\n",
    "    subontology = row[8]\n",
    "    if go_term_id in subontology_go_term_dict[subontology]:\n",
    "        proteins_dict.setdefault(gene, dict()).setdefault(subontology, set()).add(go_term_id)\n",
    "        \n",
    "\"\"\"printing how the key:values are organized for every gene/protein\"\"\"\n",
    "for i in range(5):\n",
    "    print(list(proteins_dict)[i], end=\": \")\n",
    "    pp.pprint(proteins_dict[list(proteins_dict)[i]])\n",
    "print(\"\\nTotal number of genes/proteins annotated:\", len(proteins_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking into account only fully annotated genes/proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"keeping track of fully annotated genes/proteins\"\"\"\n",
    "fully_annotated_proteins_wo_iea = []\n",
    "for protein in proteins_dict:\n",
    "    if len(proteins_dict[protein]) == 3:\n",
    "        fully_annotated_proteins_wo_iea.append(protein)\n",
    "print(\"Out of {} proteins {} are (experimentally or manually) annotated by all three sub-ontologies.\".format(len(proteins_dict), len(fully_annotated_proteins_wo_iea)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Sequence Homology data<a id='6'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading species Sequence Homology data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names of the result tabular file from blastp\n",
    "column_header = ['qseqid',   # query (e.g., unknown gene) sequence id\n",
    "                 'sseqid',   # subject (e.g., reference genome) sequence id\n",
    "                 'pident',   # percentage of identical matches\n",
    "                 'length',   # alignment length (sequence overlap)\n",
    "                 'mismatch', # number of mismatches\n",
    "                 'gapopen',  # number of gap openings\n",
    "                 'qstart',   # start of alignment in query\n",
    "                 'qend',     # end of alignment in query\n",
    "                 'sstart',   # start of alignment in subject\n",
    "                 'send',     # end of alignment in subject\n",
    "                 'evalue',   # expect value\n",
    "                 'bitscore'] # bit score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sh = pd.read_csv(\"{}/{}\".format(args.sequence_homology_raw_dir, blastp_file),\n",
    "                     names=column_header , sep='\\t', header=None)\n",
    "df_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if species=='yeast':\n",
    "    df_sh['qseqid'] = df_sh.qseqid.str.split(\"|\", expand = True)[2]\n",
    "    df_sh['sseqid'] = df_sh.sseqid.str.split(\"|\", expand = True)[2]\n",
    "elif species=='human':\n",
    "    df_sh['qseqid'] = df_sh.qseqid.str.split(\"|\", expand = True)[1]\n",
    "    df_sh['sseqid'] = df_sh.sseqid.str.split(\"|\", expand = True)[1]\n",
    "df_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sh = df_sh.iloc[:,[0, 1, 10, 11]]\n",
    "#df_sh = df_sh[df_sh['evalue'] < args.epectation_value]\n",
    "df_sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ID Mapping from \"UniProtKB AC/ID\" to \"Gene name\" (only for yeast)\n",
    "For mor information refer to :[https://www.uniprot.org/help/api_idmapping](https://www.uniprot.org/help/api_idmapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if species=='yeast':\n",
    "    \"\"\"first, collecting all 'UniProtKB AC/ID' ids\"\"\"\n",
    "    ACC_ID_ids = \" \".join(sorted(list(set(df_sh['qseqid']) | set(df_sh['sseqid']))))\n",
    "\n",
    "    import urllib.parse\n",
    "    import urllib.request\n",
    "\n",
    "    url = 'https://www.uniprot.org/uploadlists/'\n",
    "\n",
    "    params = {\n",
    "    'from': 'ACC+ID',\n",
    "    'to': 'SGD_ID',\n",
    "    'format': 'tab',\n",
    "    'query': ACC_ID_ids\n",
    "    }\n",
    "\n",
    "    data = urllib.parse.urlencode(params)\n",
    "    data = data.encode('utf-8')\n",
    "    req = urllib.request.Request(url, data)\n",
    "    with urllib.request.urlopen(req) as f:\n",
    "        response = f.read()\n",
    "\n",
    "    GENENAME_ids = {} # Gene name ids as values\n",
    "    for i, mapping in enumerate(response.decode('utf-8').strip().split(\"\\n\")):\n",
    "        if i!=0: \n",
    "            id1, id2 = mapping.split(\"\\t\")\n",
    "            GENENAME_ids[id1] = id2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting fully annotated protein pairs with their bitscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_homology_dict = {}\n",
    "if species=='yeast':\n",
    "    for protein1, protein2, bitscore in zip(df_sh['qseqid'] , df_sh['sseqid'], df_sh['bitscore']):\n",
    "        if (protein1 in GENENAME_ids) and (protein2 in GENENAME_ids):\n",
    "            pr1, pr2 = GENENAME_ids[protein1], GENENAME_ids[protein2]\n",
    "            if (pr1 in fully_annotated_proteins_wo_iea) and (pr2 in fully_annotated_proteins_wo_iea):\n",
    "                sequence_homology_dict[(pr1, pr2)] = bitscore\n",
    "if species=='human':\n",
    "    for protein1, protein2, bitscore in zip(df_sh['qseqid'] , df_sh['sseqid'], df_sh['bitscore']):\n",
    "        if (protein1 in fully_annotated_proteins_wo_iea) and (protein2 in fully_annotated_proteins_wo_iea):\n",
    "            sequence_homology_dict[(protein1, protein2)] = bitscore\n",
    "\n",
    "print(\"Number of fully annotated protein pairs is (non-symetric): {}\".format(len(sequence_homology_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing LRBS and RRBS scores<a id='7'></a>\n",
    "\n",
    "LRBS = log-reciprocal BLAST score<br>\n",
    "RRBS = relative reciprocal BLAST score<br>\n",
    "\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrbs(protein1, protein2):\n",
    "    \"\"\"function that computes and returns the log-reciprocal BLAST score between input genes\"\"\"\n",
    "    numerator = sequence_homology_dict[(protein1, protein2)] + sequence_homology_dict[(protein2, protein1)]\n",
    "    return np.log10(numerator/2)\n",
    "\n",
    "def rrbs(protein1, gene2):\n",
    "    \"\"\"function that computes and returns the relative reciprocal BLAST score between input genes\"\"\"\n",
    "    numerator = sequence_homology_dict[(protein1, protein2)] + sequence_homology_dict[(protein2, protein1)]\n",
    "    denominator = sequence_homology_dict[(protein1, protein1)] + sequence_homology_dict[(protein2, protein2)]\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrbs_rrbs_results = {}\n",
    "for protein1, protein2 in sequence_homology_dict:\n",
    "    if (protein2, protein1) in sequence_homology_dict and protein1!=protein2 and (protein2, protein1) not in lrbs_rrbs_results:\n",
    "        lrbs_rrbs_results[(protein1, protein2)] = {'lrbs': lrbs(protein1, protein2), 'rrbs': rrbs(protein1, protein2)}\n",
    "\n",
    "print(\"Number of protein pairs for sequence homology experiment ({}): {}\".format(species, len(lrbs_rrbs_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the results<a id='8'></a>\n",
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{args.result_sequence_homology_dir}/{species}_sequence_homology.tsv', 'w') as fw:\n",
    "    fw.write(\"Protein_1\\tProtein_2\\tLRBS\\tRRBS\\n\")\n",
    "    for protein1, protein2 in sorted(lrbs_rrbs_results):\n",
    "        fw.write(\"{}\\t{}\\t{}\\t{}\\n\".format(protein1, protein2, \n",
    "                                        lrbs_rrbs_results[(protein1, protein2)]['lrbs'],\n",
    "                                        lrbs_rrbs_results[(protein1, protein2)]['rrbs']\n",
    "                                       ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{args.result_sequence_homology_dir}/{species}_sequence_homology.tsv\", sep=\"\\t\", dtype=str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_genes = set(list(df.Protein_1) + list(df.Protein_2))\n",
    "print(f\"Number of {species} genes:\", len(sh_genes))\n",
    "with open(f'{args.result_sequence_homology_dir}/{species}_sequence_homology_genes.tsv', 'w') as fw:\n",
    "    for gene in sorted(sh_genes):\n",
    "        fw.write(f\"{gene}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)<br>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepSimDEF_env]",
   "language": "python",
   "name": "conda-env-deepSimDEF_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

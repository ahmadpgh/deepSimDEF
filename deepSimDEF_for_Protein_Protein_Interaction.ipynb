{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepSimDEF for Prediction of Protein-Protein Interactions (PPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from scipy.stats.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from deepSimDEF.tools.PPI_data_provider import gene_pair_data_reader, input_data_maker\n",
    "from deepSimDEF.tools.PPI_model_saver import save_model, save_embeddings\n",
    "from deepSimDEF.netwroks.PPI_network import PPI_model_builder\n",
    "\n",
    "np.random.seed(321)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting variables, reading GO annotations of genes, and preparing them for networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Biolobical Process (BP) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Found 3054 unique tokens in BP\n",
      "Top 10 Most Frequent GO terms annotating sequences in BP:\n",
      "  >>> GO0006810     1\n",
      "  >>> GO0006351     2\n",
      "  >>> GO0006355     3\n",
      "  >>> GO0015031     4\n",
      "  >>> GO0055114     5\n",
      "  >>> GO0007049     6\n",
      "  >>> GO0006414     7\n",
      "  >>> GO0008152     8\n",
      "  >>> GO0006412     9\n",
      "  >>> GO0055085     10\n",
      "Number of annotated gene products by 'BP' terms: 5680\n",
      "Maximum annotation length of one gene product ('BP' sub-ontology): 44\n",
      "Index/line of the gene product with maximum annotations ('BP' sub-ontology): 294\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Cellular Component (CC) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Found 782 unique tokens in CC\n",
      "Top 10 Most Frequent GO terms annotating sequences in CC:\n",
      "  >>> GO0005737     1\n",
      "  >>> GO0005634     2\n",
      "  >>> GO0016020     3\n",
      "  >>> GO0016021     4\n",
      "  >>> GO0005739     5\n",
      "  >>> GO0005829     6\n",
      "  >>> GO0005783     7\n",
      "  >>> GO0005886     8\n",
      "  >>> GO0005789     9\n",
      "  >>> GO0005730     10\n",
      "Number of annotated gene products by 'CC' terms: 5971\n",
      "Maximum annotation length of one gene product ('CC' sub-ontology): 17\n",
      "Index/line of the gene product with maximum annotations ('CC' sub-ontology): 5290\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Molecular Function (MF) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Found 1966 unique tokens in MF\n",
      "Top 10 Most Frequent GO terms annotating sequences in MF:\n",
      "  >>> GO0000166     1\n",
      "  >>> GO0046872     2\n",
      "  >>> GO0016740     3\n",
      "  >>> GO0005524     4\n",
      "  >>> GO0016787     5\n",
      "  >>> GO0003677     6\n",
      "  >>> GO0003723     7\n",
      "  >>> GO0003824     8\n",
      "  >>> GO0030533     9\n",
      "  >>> GO0003676     10\n",
      "Number of annotated gene products by 'MF' terms: 4856\n",
      "Maximum annotation length of one gene product ('MF' sub-ontology): 33\n",
      "Index/line of the gene product with maximum annotations ('MF' sub-ontology): 1179\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Number of fully annotated gene products: 4658\n"
     ]
    }
   ],
   "source": [
    "FOLD = 10\n",
    "DROPOUT = 0.3\n",
    "MAX_POOL = True\n",
    "\n",
    "PRE_TRAINED = True\n",
    "UPDATABLE = True\n",
    "\n",
    "ACTIVATION_HIDDEN = 'relu'\n",
    "ACTIVATION_HIGHWAY = 'sigmoid'\n",
    "ACTIVATION_OUTPUT = 'sigmoid'\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 256\n",
    "OPTIMIZER = 'adadelta'\n",
    "\n",
    "IEA = True\n",
    "SEQ = False\n",
    "\n",
    "TRANSFER_LEARNING = False\n",
    "\n",
    "SAVE_MODEL = True\n",
    "SAVE_EMBEDDINGS = True\n",
    "\n",
    "SUB_ONTOLOGY = ['BP', 'CC', 'MF']\n",
    "SUB_ONTOLOGY_work = ['BP', 'CC', 'MF']\n",
    "\n",
    "WITH_HIGH_THROUPUT = False\n",
    "\n",
    "SBOs = {}\n",
    "for sbo in SUB_ONTOLOGY_work:\n",
    "    if sbo == 'BP':\n",
    "        SBOs[sbo] = 'Biolobical Process (BP)'\n",
    "    elif sbo == 'CC':\n",
    "        SBOs[sbo] = 'Cellular Component (CC)'\n",
    "    elif sbo == 'MF':\n",
    "        SBOs[sbo] = 'Molecular Function (MF)'\n",
    "    \n",
    "WE = {}\n",
    "embedding_save = {}\n",
    "MAX_SEQUENCE_LENGTH = {}\n",
    "MAX_SEQUENCE_LENGTH_INDEX = {}\n",
    "sequences = {}\n",
    "word_indeces = {}\n",
    "protein_index = {}    \n",
    "    \n",
    "for sbo in SUB_ONTOLOGY:\n",
    "    WE[sbo] = 'deepSimDEF/embeddings/GO_' + sbo + '_Embeddings_100D.emb'\n",
    "    embedding_save[sbo] = 'GO_' + sbo + '_Embeddings_100D_Updated'\n",
    "    MAX_SEQUENCE_LENGTH[sbo] = 0\n",
    "    MAX_SEQUENCE_LENGTH_INDEX[sbo] = []\n",
    "    sequences[sbo] = []\n",
    "    word_indeces[sbo] = []\n",
    "    protein_index[sbo] = {}\n",
    "    \n",
    "    if IEA:\n",
    "        file_reader = open('deepSimDEF/gene_annotations/gene_product_GO_terms_with_IEA' + '.' + sbo)\n",
    "    else:\n",
    "        file_reader = open('deepSimDEF/gene_annotations/gene_product_GO_terms_without_IEA' + '.' + sbo)\n",
    "    \n",
    "    index_counter = 1\n",
    "    texts = []\n",
    "    for line in file_reader:\n",
    "        values = line.rstrip().replace(':', '').split()\n",
    "        protein_index[sbo][values[0]] = index_counter\n",
    "        if len(values[1:]) > MAX_SEQUENCE_LENGTH[sbo]:\n",
    "            MAX_SEQUENCE_LENGTH[sbo] = len(values[1:])\n",
    "            MAX_SEQUENCE_LENGTH_INDEX[sbo] = index_counter\n",
    "        texts.append(' '.join(values[1:]))\n",
    "        index_counter += 1\n",
    "        \n",
    "    tokenizer = Tokenizer(lower=False, num_words=0)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences[sbo] = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_indeces[sbo] = tokenizer.word_index\n",
    "    \n",
    "    if sbo == 'BP':\n",
    "        print \"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Biolobical Process (BP) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
    "    elif sbo == 'CC':\n",
    "        print \"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Cellular Component (CC) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
    "    elif sbo == 'MF':\n",
    "        print \"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Molecular Function (MF) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
    "            \n",
    "    print \"Found \" + str(len(word_indeces[sbo])) + \" unique tokens in \" + sbo\n",
    "\n",
    "    MOST_FREQUENT_LEVEL = 10\n",
    "    print 'Top', MOST_FREQUENT_LEVEL, 'Most Frequent GO terms annotating sequences in', sbo + \":\"\n",
    "    for GO_ID, indx in sorted(word_indeces[sbo].items(), key=operator.itemgetter(1))[:MOST_FREQUENT_LEVEL]:\n",
    "        print '  >>>', GO_ID, '   ' ,indx\n",
    "        \n",
    "    print \"Number of annotated gene products by '\" + sbo + \"' terms: \" + str(len(sequences[sbo]))\n",
    "    print \"Maximum annotation length of one gene product ('\" + sbo + \"' sub-ontology):\", MAX_SEQUENCE_LENGTH[sbo]\n",
    "    print \"Index/line of the gene product with maximum annotations ('\" + sbo + \"' sub-ontology):\", MAX_SEQUENCE_LENGTH_INDEX[sbo]\n",
    "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\"\n",
    "    \n",
    "    file_reader.close()\n",
    "    \n",
    "    \n",
    "fully_annotated_sequences = []   # we keep only those genes for which we have annatoation from all ontologies (defined in SUB_ONTOLOGY variable)\n",
    "for sbo in SUB_ONTOLOGY:\n",
    "    fully_annotated_sequences.append(protein_index[sbo].keys())\n",
    "fully_annotated_sequences = list(set(fully_annotated_sequences[0]).intersection(*fully_annotated_sequences))\n",
    "print \"Number of fully annotated gene products:\", len(fully_annotated_sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the gene-pair PPIs: manually curated PPIs and high-throughput PPIs (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor 1 (BP): (32956, 44)\n",
      "Shape of data tensor 2 (BP): (32956, 44)\n",
      "Shape of similarity tensor (BP): (32956,) \n",
      "\n",
      "Shape of data tensor 1 (CC): (32956, 17)\n",
      "Shape of data tensor 2 (CC): (32956, 17)\n",
      "Shape of similarity tensor (CC): (32956,) \n",
      "\n",
      "Shape of data tensor 1 (MF): (32956, 33)\n",
      "Shape of data tensor 2 (MF): (32956, 33)\n",
      "Shape of similarity tensor (MF): (32956,) \n",
      "\n",
      "Number of positive classes/interactions: 16478\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_data_dir = 'deepSimDEF/datasets/PPI_data/PPI_FULL_physical_interactions_manually_curated'\n",
    "annotation_G1_dic_MC, annotation_G2_dic_MC, interaction_pr_list_MC = gene_pair_data_reader(data_dir=input_data_dir, \n",
    "                                                                                           SUB_ONTOLOGY_work=SUB_ONTOLOGY_work, \n",
    "                                                                                           fully_annotated_sequences=fully_annotated_sequences, \n",
    "                                                                                           sequences=sequences, \n",
    "                                                                                           protein_index=protein_index,\n",
    "                                                                                           MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "VALIDATION_SPLIT = 1.0/FOLD\n",
    "indices = np.arange(annotation_G1_dic_MC[sbo].shape[0])\n",
    "np.random.shuffle(indices)\n",
    "test_size = int(VALIDATION_SPLIT * annotation_G1_dic_MC[sbo].shape[0])\n",
    "\n",
    "\n",
    "annotation_G1_dic_HT = []\n",
    "annotation_G2_dic_HT = []\n",
    "interaction_pr_list_HT = []\n",
    "\n",
    "if WITH_HIGH_THROUPUT:\n",
    "    input_data_dir = 'deepSimDEF/datasets/PPI_data/PPI_FULL_physical_interactions_high_throughput'\n",
    "    annotation_G1_dic_HT, annotation_G2_dic_HT, interaction_pr_list_HT = gene_pair_data_reader(data_dir=input_data_dir, \n",
    "                                                                                               SUB_ONTOLOGY_work=SUB_ONTOLOGY_work, \n",
    "                                                                                               fully_annotated_sequences=fully_annotated_sequences, \n",
    "                                                                                               sequences=sequences, \n",
    "                                                                                               protein_index=protein_index,\n",
    "                                                                                               MAX_SEQUENCE_LENGTH= MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## printing some information about the setting of the network and the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@ Biolobical Process (BP) @@@\n",
      "@@@ Cellular Component (CC) @@@\n",
      "@@@ Molecular Function (MF) @@@\n",
      "^^^ With IEA ^^^\n",
      "%%% Optimizer: adadelta %%%\n",
      "+++ Pre-trained (updatable) +++\n"
     ]
    }
   ],
   "source": [
    "for sbo in SUB_ONTOLOGY_work:\n",
    "    print \"@@@ \" + SBOs[sbo] + \" @@@\"\n",
    "\n",
    "if IEA:\n",
    "    print \"^^^ With IEA ^^^\"\n",
    "else:\n",
    "    print \"^^^ Without IEA ^^^\"\n",
    "\n",
    "print \"%%% Optimizer:\", OPTIMIZER, \"%%%\"\n",
    "\n",
    "if PRE_TRAINED:\n",
    "    if UPDATABLE:\n",
    "        print \"+++ Pre-trained (updatable) +++\"\n",
    "    else:\n",
    "        print \"+++ Pre-trained (not updatable) +++\"\n",
    "else:\n",
    "    print \"+++ NOT Pre-trained +++\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a 10-fold cross-validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 29375 word vectors for BP (Model 1)\n",
      "Loaded 4046 word vectors for CC (Model 1)\n",
      "Loaded 10541 word vectors for MF (Model 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/keras/legacy/layers.py:652: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold Number 1 Instantiated!!\n",
      "\n",
      "Loaded 29375 word vectors for BP (Model 2)\n",
      "Loaded 4046 word vectors for CC (Model 2)\n",
      "Loaded 10541 word vectors for MF (Model 2)\n",
      "Model for Fold Number 2 Instantiated!!\n",
      "\n",
      "Loaded 29375 word vectors for BP (Model 3)\n",
      "Loaded 4046 word vectors for CC (Model 3)\n",
      "Loaded 10541 word vectors for MF (Model 3)\n",
      "Model for Fold Number 3 Instantiated!!\n",
      "\n",
      "Loaded 29375 word vectors for BP (Model 4)\n",
      "Loaded 4046 word vectors for CC (Model 4)\n",
      "Loaded 10541 word vectors for MF (Model 4)\n",
      "Model for Fold Number 4 Instantiated!!\n",
      "\n",
      "Loaded 29375 word vectors for BP (Model 5)\n",
      "Loaded 4046 word vectors for CC (Model 5)\n",
      "Loaded 10541 word vectors for MF (Model 5)\n",
      "Model for Fold Number 5 Instantiated!!\n",
      "\n",
      "Loaded 29375 word vectors for BP (Model 6)\n",
      "Loaded 4046 word vectors for CC (Model 6)\n",
      "Loaded 10541 word vectors for MF (Model 6)\n",
      "Model for Fold Number 6 Instantiated!!\n",
      "\n",
      "Loaded 29375 word vectors for BP (Model 7)\n",
      "Loaded 4046 word vectors for CC (Model 7)\n",
      "Loaded 10541 word vectors for MF (Model 7)\n",
      "Model for Fold Number 7 Instantiated!!\n",
      "\n",
      "Loaded 29375 word vectors for BP (Model 8)\n",
      "Loaded 4046 word vectors for CC (Model 8)\n",
      "Loaded 10541 word vectors for MF (Model 8)\n",
      "Model for Fold Number 8 Instantiated!!\n",
      "\n",
      "Loaded 29375 word vectors for BP (Model 9)\n",
      "Loaded 4046 word vectors for CC (Model 9)\n",
      "Loaded 10541 word vectors for MF (Model 9)\n",
      "Model for Fold Number 9 Instantiated!!\n",
      "\n",
      "Loaded 29375 word vectors for BP (Model 10)\n",
      "Loaded 4046 word vectors for CC (Model 10)\n",
      "Loaded 10541 word vectors for MF (Model 10)\n",
      "Model for Fold Number 10 Instantiated!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "embedding_layers = []\n",
    "bests = []\n",
    "thresholds = []\n",
    "B = []\n",
    "\n",
    "for m in range(0, FOLD):\n",
    "    network = PPI_model_builder(EMBEDDING_DIM, \n",
    "                                 model_ind=m, \n",
    "                                 MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH, \n",
    "                                 WORD_EMBEDDINGS=WE,\n",
    "                                 SUB_ONTOLOGY_work=SUB_ONTOLOGY_work,\n",
    "                                 word_indeces=word_indeces, \n",
    "                                 ACTIVATION_HIDDEN=ACTIVATION_HIDDEN, \n",
    "                                 ACTIVATION_HIGHWAY=ACTIVATION_HIGHWAY, \n",
    "                                 ACTIVATION_OUTPUT=ACTIVATION_OUTPUT, \n",
    "                                 DROPOUT=DROPOUT, \n",
    "                                 OPTIMIZER=OPTIMIZER)\n",
    "    models.append(network[0])\n",
    "    embedding_layers.append(network[1])\n",
    "    bests.append(0)\n",
    "    thresholds.append(0)\n",
    "    B.append({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the deepSimDEF netwrok for PPI task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 1/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5417 - fmeasure: 0.7387 - val_loss: 0.4262 - val_fmeasure: 0.8073\n",
      ">>> F1-score (1): 0.80753 Best (1): + 0.80753 (0.5 : 0.80753)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5507 - fmeasure: 0.7328 - val_loss: 0.4151 - val_fmeasure: 0.8243\n",
      ">>> F1-score (2): 0.8257 Best (2): + 0.8257 (0.5 : 0.8257)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5635 - fmeasure: 0.7244 - val_loss: 0.4478 - val_fmeasure: 0.7974\n",
      ">>> F1-score (3): 0.79813 Best (3): + 0.79813 (0.5 : 0.79813)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5498 - fmeasure: 0.7289 - val_loss: 0.4119 - val_fmeasure: 0.8293\n",
      ">>> F1-score (4): 0.82992 Best (4): + 0.82992 (0.5 : 0.82992)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5529 - fmeasure: 0.7309 - val_loss: 0.4357 - val_fmeasure: 0.8065\n",
      ">>> F1-score (5): 0.80704 Best (5): + 0.80704 (0.5 : 0.80704)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5491 - fmeasure: 0.7299 - val_loss: 0.4202 - val_fmeasure: 0.8256\n",
      ">>> F1-score (6): 0.8267 Best (6): + 0.8267 (0.5 : 0.8267)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5539 - fmeasure: 0.7302 - val_loss: 0.4306 - val_fmeasure: 0.8148\n",
      ">>> F1-score (7): 0.81512 Best (7): + 0.81512 (0.5 : 0.81512)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5444 - fmeasure: 0.7339 - val_loss: 0.4284 - val_fmeasure: 0.8118\n",
      ">>> F1-score (8): 0.81226 Best (8): + 0.81226 (0.5 : 0.81226)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5545 - fmeasure: 0.7257 - val_loss: 0.4233 - val_fmeasure: 0.8222\n",
      ">>> F1-score (9): 0.82203 Best (9): + 0.82203 (0.5 : 0.82203)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.5593 - fmeasure: 0.7287 - val_loss: 0.4334 - val_fmeasure: 0.8116\n",
      ">>> F1-score (10): 0.81185 Best (10): + 0.81185 (0.5 : 0.81185)\n",
      "\n",
      "F1-score for this epoch: 0.815628 ( 0.5 )-- Best F1-score::==> 0.815628 ( 0.5 )  (for epoch # 1 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 2/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4313 - fmeasure: 0.8089 - val_loss: 0.3798 - val_fmeasure: 0.8293\n",
      ">>> F1-score (1): 0.82934 Best (1): + 0.82934 (0.5 : 0.02181)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4315 - fmeasure: 0.8073 - val_loss: 0.3759 - val_fmeasure: 0.8391\n",
      ">>> F1-score (2): 0.84031 Best (2): + 0.84031 (0.5 : 0.01461)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4369 - fmeasure: 0.8046 - val_loss: 0.4074 - val_fmeasure: 0.8358\n",
      ">>> F1-score (3): 0.83632 Best (3): + 0.83632 (0.5 : 0.03819)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4350 - fmeasure: 0.8052 - val_loss: 0.3623 - val_fmeasure: 0.8484\n",
      ">>> F1-score (4): 0.84885 Best (4): + 0.84885 (0.5 : 0.01893)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4407 - fmeasure: 0.8021 - val_loss: 0.4067 - val_fmeasure: 0.8269\n",
      ">>> F1-score (5): 0.82769 Best (5): + 0.82769 (0.5 : 0.02065)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4356 - fmeasure: 0.8074 - val_loss: 0.3928 - val_fmeasure: 0.8398\n",
      ">>> F1-score (6): 0.84022 Best (6): + 0.84022 (0.5 : 0.01352)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4389 - fmeasure: 0.8016 - val_loss: 0.4057 - val_fmeasure: 0.8278\n",
      ">>> F1-score (7): 0.82829 Best (7): + 0.82829 (0.5 : 0.01317)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4364 - fmeasure: 0.8031 - val_loss: 0.3938 - val_fmeasure: 0.8259\n",
      ">>> F1-score (8): 0.82614 Best (8): + 0.82614 (0.5 : 0.01388)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4374 - fmeasure: 0.8038 - val_loss: 0.3721 - val_fmeasure: 0.8409\n",
      ">>> F1-score (9): 0.84089 Best (9): + 0.84089 (0.5 : 0.01886)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.4365 - fmeasure: 0.8041 - val_loss: 0.3872 - val_fmeasure: 0.8348\n",
      ">>> F1-score (10): 0.83491 Best (10): + 0.83491 (0.5 : 0.02306)\n",
      "\n",
      "F1-score for this epoch: 0.835296 ( 0.5 )-- Best F1-score::==> 0.835296 ( 0.5 )  (for epoch # 2 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 3/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3869 - fmeasure: 0.8346 - val_loss: 0.3454 - val_fmeasure: 0.8523\n",
      ">>> F1-score (1): 0.85255 Best (1): + 0.85255 (0.5 : 0.02321)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3879 - fmeasure: 0.8329 - val_loss: 0.3500 - val_fmeasure: 0.8573\n",
      ">>> F1-score (2): 0.85846 Best (2): + 0.85846 (0.5 : 0.01815)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3895 - fmeasure: 0.8309 - val_loss: 0.3770 - val_fmeasure: 0.8542\n",
      ">>> F1-score (3): 0.85488 Best (3): + 0.85488 (0.5 : 0.01856)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3923 - fmeasure: 0.8288 - val_loss: 0.3484 - val_fmeasure: 0.8624\n",
      ">>> F1-score (4): 0.86241 Best (4): + 0.86241 (0.5 : 0.01356)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3923 - fmeasure: 0.8304 - val_loss: 0.3614 - val_fmeasure: 0.8438\n",
      ">>> F1-score (5): 0.84448 Best (5): + 0.84448 (0.5 : 0.01679)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3905 - fmeasure: 0.8296 - val_loss: 0.3357 - val_fmeasure: 0.8655\n",
      ">>> F1-score (6): 0.86633 Best (6): + 0.86633 (0.5 : 0.02611)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3932 - fmeasure: 0.8295 - val_loss: 0.3509 - val_fmeasure: 0.8499\n",
      ">>> F1-score (7): 0.85012 Best (7): + 0.85012 (0.5 : 0.02183)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3886 - fmeasure: 0.8302 - val_loss: 0.3699 - val_fmeasure: 0.8557\n",
      ">>> F1-score (8): 0.85617 Best (8): + 0.85617 (0.5 : 0.03003)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3927 - fmeasure: 0.8305 - val_loss: 0.3713 - val_fmeasure: 0.8512\n",
      ">>> F1-score (9): 0.85146 Best (9): + 0.85146 (0.5 : 0.01057)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3929 - fmeasure: 0.8291 - val_loss: 0.3568 - val_fmeasure: 0.8586\n",
      ">>> F1-score (10): 0.8587 Best (10): + 0.8587 (0.5 : 0.02379)\n",
      "\n",
      "F1-score for this epoch: 0.855556 ( 0.5 )-- Best F1-score::==> 0.855556 ( 0.5 )  (for epoch # 3 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 4/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59322/59322 [==============================] - 3s - loss: 0.3586 - fmeasure: 0.8486 - val_loss: 0.3418 - val_fmeasure: 0.8588\n",
      ">>> F1-score (1): 0.8592 Best (1): + 0.8592 (0.5 : 0.00665)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3579 - fmeasure: 0.8491 - val_loss: 0.3273 - val_fmeasure: 0.8584\n",
      ">>> F1-score (2): 0.85951 Best (2): + 0.85951 (0.5 : 0.00105)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3576 - fmeasure: 0.8489 - val_loss: 0.3505 - val_fmeasure: 0.8599\n",
      ">>> F1-score (3): 0.86059 Best (3): + 0.86059 (0.5 : 0.00571)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3609 - fmeasure: 0.8473 - val_loss: 0.3143 - val_fmeasure: 0.8755\n",
      ">>> F1-score (4): 0.87562 Best (4): + 0.87562 (0.5 : 0.01321)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3631 - fmeasure: 0.8452 - val_loss: 0.3429 - val_fmeasure: 0.8582\n",
      ">>> F1-score (5): 0.85884 Best (5): + 0.85884 (0.5 : 0.01436)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3614 - fmeasure: 0.8465 - val_loss: 0.3163 - val_fmeasure: 0.8733\n",
      ">>> F1-score (6): 0.87346 Best (6): + 0.87346 (0.5 : 0.00713)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3621 - fmeasure: 0.8480 - val_loss: 0.3299 - val_fmeasure: 0.8630\n",
      ">>> F1-score (7): 0.86327 Best (7): + 0.86327 (0.5 : 0.01315)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3613 - fmeasure: 0.8469 - val_loss: 0.3325 - val_fmeasure: 0.8660\n",
      ">>> F1-score (8): 0.86659 Best (8): + 0.86659 (0.5 : 0.01042)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3615 - fmeasure: 0.8465 - val_loss: 0.3359 - val_fmeasure: 0.8687\n",
      ">>> F1-score (9): 0.86889 Best (9): + 0.86889 (0.5 : 0.01743)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3621 - fmeasure: 0.8450 - val_loss: 0.3395 - val_fmeasure: 0.8664\n",
      ">>> F1-score (10): 0.86657 Best (10): + 0.86657 (0.5 : 0.00787)\n",
      "\n",
      "F1-score for this epoch: 0.865254 ( 0.5 )-- Best F1-score::==> 0.865254 ( 0.5 )  (for epoch # 4 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 5/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3360 - fmeasure: 0.8608 - val_loss: 0.3079 - val_fmeasure: 0.8697\n",
      ">>> F1-score (1): 0.87036 Best (1): + 0.87036 (0.5 : 0.01116)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3348 - fmeasure: 0.8608 - val_loss: 0.3155 - val_fmeasure: 0.8688\n",
      ">>> F1-score (2): 0.86982 Best (2): + 0.86982 (0.5 : 0.01031)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3330 - fmeasure: 0.8617 - val_loss: 0.3325 - val_fmeasure: 0.8645\n",
      ">>> F1-score (3): 0.86503 Best (3): + 0.86503 (0.5 : 0.00444)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3356 - fmeasure: 0.8590 - val_loss: 0.3016 - val_fmeasure: 0.8807\n",
      ">>> F1-score (4): 0.88044 Best (4): + 0.88044 (0.5 : 0.00482)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3350 - fmeasure: 0.8594 - val_loss: 0.3240 - val_fmeasure: 0.8629\n",
      ">>> F1-score (5): 0.86341 Best (5): + 0.86341 (0.5 : 0.00457)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3356 - fmeasure: 0.8581 - val_loss: 0.2990 - val_fmeasure: 0.8780\n",
      ">>> F1-score (6): 0.87881 Best (6): + 0.87881 (0.5 : 0.00535)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3365 - fmeasure: 0.8590 - val_loss: 0.3128 - val_fmeasure: 0.8713\n",
      ">>> F1-score (7): 0.87156 Best (7): + 0.87156 (0.5 : 0.00829)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3356 - fmeasure: 0.8598 - val_loss: 0.3229 - val_fmeasure: 0.8626\n",
      ">>> F1-score (8): 0.86327 Best (8): - 0.86659 (0.5 : -0.00332)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3397 - fmeasure: 0.8576 - val_loss: 0.3226 - val_fmeasure: 0.8732\n",
      ">>> F1-score (9): 0.87352 Best (9): + 0.87352 (0.5 : 0.00463)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3375 - fmeasure: 0.8591 - val_loss: 0.3257 - val_fmeasure: 0.8757\n",
      ">>> F1-score (10): 0.87601 Best (10): + 0.87601 (0.5 : 0.00944)\n",
      "\n",
      "F1-score for this epoch: 0.871223 ( 0.5 )-- Best F1-score::==> 0.871223 ( 0.5 )  (for epoch # 5 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 6/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3169 - fmeasure: 0.8697 - val_loss: 0.2973 - val_fmeasure: 0.8811\n",
      ">>> F1-score (1): 0.88169 Best (1): + 0.88169 (0.5 : 0.01133)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3141 - fmeasure: 0.8701 - val_loss: 0.3009 - val_fmeasure: 0.8774\n",
      ">>> F1-score (2): 0.87826 Best (2): + 0.87826 (0.5 : 0.00844)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3155 - fmeasure: 0.8680 - val_loss: 0.3364 - val_fmeasure: 0.8729\n",
      ">>> F1-score (3): 0.87342 Best (3): + 0.87342 (0.5 : 0.00839)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3166 - fmeasure: 0.8700 - val_loss: 0.2952 - val_fmeasure: 0.8838\n",
      ">>> F1-score (4): 0.88352 Best (4): + 0.88352 (0.5 : 0.00308)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3164 - fmeasure: 0.8693 - val_loss: 0.3122 - val_fmeasure: 0.8764\n",
      ">>> F1-score (5): 0.87689 Best (5): + 0.87689 (0.5 : 0.01348)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3162 - fmeasure: 0.8701 - val_loss: 0.2830 - val_fmeasure: 0.8849\n",
      ">>> F1-score (6): 0.88591 Best (6): + 0.88591 (0.5 : 0.0071)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3157 - fmeasure: 0.8708 - val_loss: 0.2953 - val_fmeasure: 0.8714\n",
      ">>> F1-score (7): 0.8717 Best (7): + 0.8717 (0.5 : 0.00014)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3174 - fmeasure: 0.8686 - val_loss: 0.3022 - val_fmeasure: 0.8808\n",
      ">>> F1-score (8): 0.88129 Best (8): + 0.88129 (0.5 : 0.0147)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3185 - fmeasure: 0.8666 - val_loss: 0.3097 - val_fmeasure: 0.8803\n",
      ">>> F1-score (9): 0.88045 Best (9): + 0.88045 (0.5 : 0.00693)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3186 - fmeasure: 0.8684 - val_loss: 0.3073 - val_fmeasure: 0.8807\n",
      ">>> F1-score (10): 0.88089 Best (10): + 0.88089 (0.5 : 0.00488)\n",
      "\n",
      "F1-score for this epoch: 0.879402 ( 0.5 )-- Best F1-score::==> 0.879402 ( 0.5 )  (for epoch # 6 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 7/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59322/59322 [==============================] - 3s - loss: 0.2993 - fmeasure: 0.8783 - val_loss: 0.2884 - val_fmeasure: 0.8759\n",
      ">>> F1-score (1): 0.87624 Best (1): - 0.88169 (0.5 : -0.00545)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2976 - fmeasure: 0.8786 - val_loss: 0.2932 - val_fmeasure: 0.8769\n",
      ">>> F1-score (2): 0.87786 Best (2): - 0.87826 (0.5 : -0.0004)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2987 - fmeasure: 0.8782 - val_loss: 0.3174 - val_fmeasure: 0.8761\n",
      ">>> F1-score (3): 0.87667 Best (3): + 0.87667 (0.5 : 0.00325)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3014 - fmeasure: 0.8768 - val_loss: 0.2659 - val_fmeasure: 0.8972\n",
      ">>> F1-score (4): 0.89663 Best (4): + 0.89663 (0.5 : 0.01311)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2999 - fmeasure: 0.8756 - val_loss: 0.3078 - val_fmeasure: 0.8785\n",
      ">>> F1-score (5): 0.879 Best (5): + 0.879 (0.5 : 0.00211)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3003 - fmeasure: 0.8768 - val_loss: 0.2732 - val_fmeasure: 0.8939\n",
      ">>> F1-score (6): 0.8944 Best (6): + 0.8944 (0.5 : 0.00849)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2984 - fmeasure: 0.8789 - val_loss: 0.2869 - val_fmeasure: 0.8814\n",
      ">>> F1-score (7): 0.88173 Best (7): + 0.88173 (0.5 : 0.01003)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3020 - fmeasure: 0.8755 - val_loss: 0.2964 - val_fmeasure: 0.8777\n",
      ">>> F1-score (8): 0.87799 Best (8): - 0.88129 (0.5 : -0.0033)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3000 - fmeasure: 0.8773 - val_loss: 0.2998 - val_fmeasure: 0.8809\n",
      ">>> F1-score (9): 0.88136 Best (9): + 0.88136 (0.5 : 0.00091)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.3008 - fmeasure: 0.8780 - val_loss: 0.2994 - val_fmeasure: 0.8734\n",
      ">>> F1-score (10): 0.87332 Best (10): - 0.88089 (0.5 : -0.00757)\n",
      "\n",
      "F1-score for this epoch: 0.88152 ( 0.5 )-- Best F1-score::==> 0.88152 ( 0.5 )  (for epoch # 7 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 8/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2839 - fmeasure: 0.8840 - val_loss: 0.2806 - val_fmeasure: 0.8865\n",
      ">>> F1-score (1): 0.88682 Best (1): + 0.88682 (0.5 : 0.00513)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2841 - fmeasure: 0.8848 - val_loss: 0.2942 - val_fmeasure: 0.8826\n",
      ">>> F1-score (2): 0.88336 Best (2): + 0.88336 (0.5 : 0.0051)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2840 - fmeasure: 0.8844 - val_loss: 0.3011 - val_fmeasure: 0.8761\n",
      ">>> F1-score (3): 0.8769 Best (3): + 0.8769 (0.5 : 0.00023)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2855 - fmeasure: 0.8843 - val_loss: 0.2584 - val_fmeasure: 0.8977\n",
      ">>> F1-score (4): 0.89717 Best (4): + 0.89717 (0.5 : 0.00054)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2833 - fmeasure: 0.8844 - val_loss: 0.2907 - val_fmeasure: 0.8847\n",
      ">>> F1-score (5): 0.885 Best (5): + 0.885 (0.5 : 0.006)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2871 - fmeasure: 0.8839 - val_loss: 0.2688 - val_fmeasure: 0.8934\n",
      ">>> F1-score (6): 0.89416 Best (6): - 0.8944 (0.5 : -0.00024)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2865 - fmeasure: 0.8840 - val_loss: 0.2851 - val_fmeasure: 0.8814\n",
      ">>> F1-score (7): 0.88166 Best (7): - 0.88173 (0.5 : -7e-05)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2867 - fmeasure: 0.8832 - val_loss: 0.2886 - val_fmeasure: 0.8854\n",
      ">>> F1-score (8): 0.88603 Best (8): + 0.88603 (0.5 : 0.00474)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2859 - fmeasure: 0.8838 - val_loss: 0.2905 - val_fmeasure: 0.8878\n",
      ">>> F1-score (9): 0.88808 Best (9): + 0.88808 (0.5 : 0.00672)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2847 - fmeasure: 0.8849 - val_loss: 0.2832 - val_fmeasure: 0.8905\n",
      ">>> F1-score (10): 0.89068 Best (10): + 0.89068 (0.5 : 0.00979)\n",
      "\n",
      "F1-score for this epoch: 0.886986 ( 0.5 )-- Best F1-score::==> 0.886986 ( 0.5 )  (for epoch # 8 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 9/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2721 - fmeasure: 0.8912 - val_loss: 0.2709 - val_fmeasure: 0.8947\n",
      ">>> F1-score (1): 0.89504 Best (1): + 0.89504 (0.5 : 0.00822)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2732 - fmeasure: 0.8896 - val_loss: 0.2793 - val_fmeasure: 0.8875\n",
      ">>> F1-score (2): 0.88837 Best (2): + 0.88837 (0.5 : 0.00501)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2727 - fmeasure: 0.8905 - val_loss: 0.2960 - val_fmeasure: 0.8813\n",
      ">>> F1-score (3): 0.88179 Best (3): + 0.88179 (0.5 : 0.00489)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2725 - fmeasure: 0.8910 - val_loss: 0.2509 - val_fmeasure: 0.9010\n",
      ">>> F1-score (4): 0.9006 Best (4): + 0.9006 (0.5 : 0.00343)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2703 - fmeasure: 0.8916 - val_loss: 0.2855 - val_fmeasure: 0.8854\n",
      ">>> F1-score (5): 0.88579 Best (5): + 0.88579 (0.5 : 0.00079)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2739 - fmeasure: 0.8891 - val_loss: 0.2605 - val_fmeasure: 0.8991\n",
      ">>> F1-score (6): 0.89976 Best (6): + 0.89976 (0.5 : 0.00536)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2743 - fmeasure: 0.8903 - val_loss: 0.2742 - val_fmeasure: 0.8833\n",
      ">>> F1-score (7): 0.8834 Best (7): + 0.8834 (0.5 : 0.00167)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2744 - fmeasure: 0.8898 - val_loss: 0.2834 - val_fmeasure: 0.8930\n",
      ">>> F1-score (8): 0.89358 Best (8): + 0.89358 (0.5 : 0.00755)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2727 - fmeasure: 0.8890 - val_loss: 0.2827 - val_fmeasure: 0.8923\n",
      ">>> F1-score (9): 0.89247 Best (9): + 0.89247 (0.5 : 0.00439)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2736 - fmeasure: 0.8896 - val_loss: 0.2768 - val_fmeasure: 0.8966\n",
      ">>> F1-score (10): 0.89692 Best (10): + 0.89692 (0.5 : 0.00624)\n",
      "\n",
      "F1-score for this epoch: 0.891772 ( 0.5 )-- Best F1-score::==> 0.891772 ( 0.5 )  (for epoch # 9 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 10/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2609 - fmeasure: 0.8944 - val_loss: 0.2656 - val_fmeasure: 0.8894\n",
      ">>> F1-score (1): 0.88964 Best (1): - 0.89504 (0.5 : -0.0054)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59322/59322 [==============================] - 3s - loss: 0.2609 - fmeasure: 0.8945 - val_loss: 0.2730 - val_fmeasure: 0.8896\n",
      ">>> F1-score (2): 0.89022 Best (2): + 0.89022 (0.5 : 0.00185)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2593 - fmeasure: 0.8950 - val_loss: 0.3012 - val_fmeasure: 0.8832\n",
      ">>> F1-score (3): 0.88379 Best (3): + 0.88379 (0.5 : 0.002)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2556 - fmeasure: 0.8985 - val_loss: 0.2461 - val_fmeasure: 0.9040\n",
      ">>> F1-score (4): 0.90376 Best (4): + 0.90376 (0.5 : 0.00316)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2578 - fmeasure: 0.8960 - val_loss: 0.2877 - val_fmeasure: 0.8896\n",
      ">>> F1-score (5): 0.88994 Best (5): + 0.88994 (0.5 : 0.00415)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2629 - fmeasure: 0.8944 - val_loss: 0.2640 - val_fmeasure: 0.9029\n",
      ">>> F1-score (6): 0.90338 Best (6): + 0.90338 (0.5 : 0.00362)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2608 - fmeasure: 0.8959 - val_loss: 0.2682 - val_fmeasure: 0.8872\n",
      ">>> F1-score (7): 0.88736 Best (7): + 0.88736 (0.5 : 0.00396)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2637 - fmeasure: 0.8937 - val_loss: 0.2679 - val_fmeasure: 0.8920\n",
      ">>> F1-score (8): 0.89244 Best (8): - 0.89358 (0.5 : -0.00114)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2578 - fmeasure: 0.8973 - val_loss: 0.2811 - val_fmeasure: 0.8926\n",
      ">>> F1-score (9): 0.89262 Best (9): + 0.89262 (0.5 : 0.00015)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2625 - fmeasure: 0.8955 - val_loss: 0.2785 - val_fmeasure: 0.8924\n",
      ">>> F1-score (10): 0.89275 Best (10): - 0.89692 (0.5 : -0.00417)\n",
      "\n",
      "F1-score for this epoch: 0.89259 ( 0.5 )-- Best F1-score::==> 0.89259 ( 0.5 )  (for epoch # 10 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 11/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2515 - fmeasure: 0.8995 - val_loss: 0.2641 - val_fmeasure: 0.8975\n",
      ">>> F1-score (1): 0.89786 Best (1): + 0.89786 (0.5 : 0.00282)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2501 - fmeasure: 0.9006 - val_loss: 0.2706 - val_fmeasure: 0.8895\n",
      ">>> F1-score (2): 0.89011 Best (2): - 0.89022 (0.5 : -0.00011)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2492 - fmeasure: 0.8993 - val_loss: 0.2793 - val_fmeasure: 0.8865\n",
      ">>> F1-score (3): 0.88682 Best (3): + 0.88682 (0.5 : 0.00303)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2503 - fmeasure: 0.9008 - val_loss: 0.2377 - val_fmeasure: 0.9080\n",
      ">>> F1-score (4): 0.9078 Best (4): + 0.9078 (0.5 : 0.00404)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2476 - fmeasure: 0.9019 - val_loss: 0.2755 - val_fmeasure: 0.8947\n",
      ">>> F1-score (5): 0.89496 Best (5): + 0.89496 (0.5 : 0.00502)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2505 - fmeasure: 0.9006 - val_loss: 0.2528 - val_fmeasure: 0.8974\n",
      ">>> F1-score (6): 0.89813 Best (6): - 0.90338 (0.5 : -0.00525)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2509 - fmeasure: 0.9011 - val_loss: 0.2638 - val_fmeasure: 0.8916\n",
      ">>> F1-score (7): 0.8919 Best (7): + 0.8919 (0.5 : 0.00454)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2536 - fmeasure: 0.8982 - val_loss: 0.2698 - val_fmeasure: 0.8978\n",
      ">>> F1-score (8): 0.89851 Best (8): + 0.89851 (0.5 : 0.00493)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2496 - fmeasure: 0.8997 - val_loss: 0.2815 - val_fmeasure: 0.8974\n",
      ">>> F1-score (9): 0.89757 Best (9): + 0.89757 (0.5 : 0.00495)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2490 - fmeasure: 0.9010 - val_loss: 0.2663 - val_fmeasure: 0.8950\n",
      ">>> F1-score (10): 0.89507 Best (10): - 0.89692 (0.5 : -0.00185)\n",
      "\n",
      "F1-score for this epoch: 0.895873 ( 0.5 )-- Best F1-score::==> 0.895873 ( 0.5 )  (for epoch # 11 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 12/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2429 - fmeasure: 0.9036 - val_loss: 0.2529 - val_fmeasure: 0.8975\n",
      ">>> F1-score (1): 0.8978 Best (1): - 0.89786 (0.5 : -6e-05)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2395 - fmeasure: 0.9043 - val_loss: 0.2652 - val_fmeasure: 0.8976\n",
      ">>> F1-score (2): 0.89807 Best (2): + 0.89807 (0.5 : 0.00785)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2387 - fmeasure: 0.9056 - val_loss: 0.2855 - val_fmeasure: 0.8868\n",
      ">>> F1-score (3): 0.88722 Best (3): + 0.88722 (0.5 : 0.0004)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2399 - fmeasure: 0.9044 - val_loss: 0.2435 - val_fmeasure: 0.9018\n",
      ">>> F1-score (4): 0.90152 Best (4): - 0.9078 (0.5 : -0.00628)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2398 - fmeasure: 0.9053 - val_loss: 0.2751 - val_fmeasure: 0.8897\n",
      ">>> F1-score (5): 0.89012 Best (5): - 0.89496 (0.5 : -0.00484)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2412 - fmeasure: 0.9041 - val_loss: 0.2508 - val_fmeasure: 0.9007\n",
      ">>> F1-score (6): 0.9013 Best (6): - 0.90338 (0.5 : -0.00208)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2382 - fmeasure: 0.9055 - val_loss: 0.2783 - val_fmeasure: 0.8801\n",
      ">>> F1-score (7): 0.88044 Best (7): - 0.8919 (0.5 : -0.01146)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2419 - fmeasure: 0.9031 - val_loss: 0.2606 - val_fmeasure: 0.9019\n",
      ">>> F1-score (8): 0.90255 Best (8): + 0.90255 (0.5 : 0.00404)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2406 - fmeasure: 0.9054 - val_loss: 0.2770 - val_fmeasure: 0.8975\n",
      ">>> F1-score (9): 0.89755 Best (9): - 0.89757 (0.5 : -2e-05)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2389 - fmeasure: 0.9058 - val_loss: 0.2621 - val_fmeasure: 0.8978\n",
      ">>> F1-score (10): 0.89797 Best (10): + 0.89797 (0.5 : 0.00105)\n",
      "\n",
      "F1-score for this epoch: 0.895454 ( 0.5 )-- Best F1-score::==> 0.895873 ( 0.5 )  (for epoch # 11 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 13/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2329 - fmeasure: 0.9079 - val_loss: 0.2565 - val_fmeasure: 0.8951\n",
      ">>> F1-score (1): 0.89516 Best (1): - 0.89786 (0.5 : -0.0027)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59322/59322 [==============================] - 3s - loss: 0.2316 - fmeasure: 0.9093 - val_loss: 0.2628 - val_fmeasure: 0.8986\n",
      ">>> F1-score (2): 0.89922 Best (2): + 0.89922 (0.5 : 0.00115)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2321 - fmeasure: 0.9076 - val_loss: 0.2763 - val_fmeasure: 0.8937\n",
      ">>> F1-score (3): 0.89409 Best (3): + 0.89409 (0.5 : 0.00687)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2298 - fmeasure: 0.9097 - val_loss: 0.2360 - val_fmeasure: 0.9082\n",
      ">>> F1-score (4): 0.90775 Best (4): - 0.9078 (0.5 : -5e-05)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2321 - fmeasure: 0.9084 - val_loss: 0.2712 - val_fmeasure: 0.8963\n",
      ">>> F1-score (5): 0.89642 Best (5): + 0.89642 (0.5 : 0.00146)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2329 - fmeasure: 0.9082 - val_loss: 0.2427 - val_fmeasure: 0.9074\n",
      ">>> F1-score (6): 0.90806 Best (6): + 0.90806 (0.5 : 0.00468)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2333 - fmeasure: 0.9075 - val_loss: 0.2528 - val_fmeasure: 0.8976\n",
      ">>> F1-score (7): 0.89763 Best (7): + 0.89763 (0.5 : 0.00573)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2336 - fmeasure: 0.9080 - val_loss: 0.2573 - val_fmeasure: 0.9001\n",
      ">>> F1-score (8): 0.90049 Best (8): - 0.90255 (0.5 : -0.00206)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2312 - fmeasure: 0.9082 - val_loss: 0.2740 - val_fmeasure: 0.8973\n",
      ">>> F1-score (9): 0.89751 Best (9): - 0.89757 (0.5 : -6e-05)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2322 - fmeasure: 0.9087 - val_loss: 0.2586 - val_fmeasure: 0.9002\n",
      ">>> F1-score (10): 0.90045 Best (10): + 0.90045 (0.5 : 0.00248)\n",
      "\n",
      "F1-score for this epoch: 0.899678 ( 0.5 )-- Best F1-score::==> 0.899678 ( 0.5 )  (for epoch # 13 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 14/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2273 - fmeasure: 0.9106 - val_loss: 0.2454 - val_fmeasure: 0.9027\n",
      ">>> F1-score (1): 0.90297 Best (1): + 0.90297 (0.5 : 0.00511)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2221 - fmeasure: 0.9118 - val_loss: 0.2727 - val_fmeasure: 0.8915\n",
      ">>> F1-score (2): 0.89229 Best (2): - 0.89922 (0.5 : -0.00693)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2243 - fmeasure: 0.9121 - val_loss: 0.2803 - val_fmeasure: 0.8929\n",
      ">>> F1-score (3): 0.89335 Best (3): - 0.89409 (0.5 : -0.00074)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2227 - fmeasure: 0.9107 - val_loss: 0.2390 - val_fmeasure: 0.9082\n",
      ">>> F1-score (4): 0.90803 Best (4): + 0.90803 (0.5 : 0.00023)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2211 - fmeasure: 0.9131 - val_loss: 0.2637 - val_fmeasure: 0.8998\n",
      ">>> F1-score (5): 0.90003 Best (5): + 0.90003 (0.5 : 0.00361)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2235 - fmeasure: 0.9119 - val_loss: 0.2452 - val_fmeasure: 0.9009\n",
      ">>> F1-score (6): 0.90194 Best (6): - 0.90806 (0.5 : -0.00612)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2228 - fmeasure: 0.9132 - val_loss: 0.2524 - val_fmeasure: 0.8985\n",
      ">>> F1-score (7): 0.89864 Best (7): + 0.89864 (0.5 : 0.00101)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2254 - fmeasure: 0.9120 - val_loss: 0.2500 - val_fmeasure: 0.9108\n",
      ">>> F1-score (8): 0.91146 Best (8): + 0.91146 (0.5 : 0.00891)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2251 - fmeasure: 0.9111 - val_loss: 0.2705 - val_fmeasure: 0.8975\n",
      ">>> F1-score (9): 0.89762 Best (9): + 0.89762 (0.5 : 5e-05)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2243 - fmeasure: 0.9103 - val_loss: 0.2569 - val_fmeasure: 0.8978\n",
      ">>> F1-score (10): 0.898 Best (10): - 0.90045 (0.5 : -0.00245)\n",
      "\n",
      "F1-score for this epoch: 0.900433 ( 0.5 )-- Best F1-score::==> 0.900433 ( 0.5 )  (for epoch # 14 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 15/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2197 - fmeasure: 0.9133 - val_loss: 0.2466 - val_fmeasure: 0.9033\n",
      ">>> F1-score (1): 0.9036 Best (1): + 0.9036 (0.5 : 0.00063)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2147 - fmeasure: 0.9147 - val_loss: 0.2541 - val_fmeasure: 0.9062\n",
      ">>> F1-score (2): 0.90666 Best (2): + 0.90666 (0.5 : 0.00744)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2133 - fmeasure: 0.9162 - val_loss: 0.2772 - val_fmeasure: 0.8993\n",
      ">>> F1-score (3): 0.89968 Best (3): + 0.89968 (0.5 : 0.00559)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2166 - fmeasure: 0.9144 - val_loss: 0.2307 - val_fmeasure: 0.9155\n",
      ">>> F1-score (4): 0.91543 Best (4): + 0.91543 (0.5 : 0.0074)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2147 - fmeasure: 0.9153 - val_loss: 0.2709 - val_fmeasure: 0.9027\n",
      ">>> F1-score (5): 0.90296 Best (5): + 0.90296 (0.5 : 0.00293)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2184 - fmeasure: 0.9130 - val_loss: 0.2447 - val_fmeasure: 0.9092\n",
      ">>> F1-score (6): 0.90973 Best (6): + 0.90973 (0.5 : 0.00167)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2159 - fmeasure: 0.9165 - val_loss: 0.2489 - val_fmeasure: 0.8993\n",
      ">>> F1-score (7): 0.8996 Best (7): + 0.8996 (0.5 : 0.00096)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2197 - fmeasure: 0.9145 - val_loss: 0.2527 - val_fmeasure: 0.9088\n",
      ">>> F1-score (8): 0.90931 Best (8): - 0.91146 (0.5 : -0.00215)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2156 - fmeasure: 0.9151 - val_loss: 0.2717 - val_fmeasure: 0.8996\n",
      ">>> F1-score (9): 0.89984 Best (9): + 0.89984 (0.5 : 0.00222)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2185 - fmeasure: 0.9142 - val_loss: 0.2550 - val_fmeasure: 0.9010\n",
      ">>> F1-score (10): 0.90111 Best (10): + 0.90111 (0.5 : 0.00066)\n",
      "\n",
      "F1-score for this epoch: 0.904792 ( 0.5 )-- Best F1-score::==> 0.904792 ( 0.5 )  (for epoch # 15 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 16/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2099 - fmeasure: 0.9167 - val_loss: 0.2420 - val_fmeasure: 0.9074\n",
      ">>> F1-score (1): 0.90756 Best (1): + 0.90756 (0.5 : 0.00396)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59322/59322 [==============================] - 3s - loss: 0.2117 - fmeasure: 0.9160 - val_loss: 0.2600 - val_fmeasure: 0.9000\n",
      ">>> F1-score (2): 0.90058 Best (2): - 0.90666 (0.5 : -0.00608)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2085 - fmeasure: 0.9183 - val_loss: 0.2758 - val_fmeasure: 0.8974\n",
      ">>> F1-score (3): 0.8979 Best (3): - 0.89968 (0.5 : -0.00178)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2087 - fmeasure: 0.9181 - val_loss: 0.2309 - val_fmeasure: 0.9113\n",
      ">>> F1-score (4): 0.91115 Best (4): - 0.91543 (0.5 : -0.00428)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.2076 - fmeasure: 0.9174 - val_loss: 0.2698 - val_fmeasure: 0.9021\n",
      ">>> F1-score (5): 0.90233 Best (5): - 0.90296 (0.5 : -0.00063)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2110 - fmeasure: 0.9165 - val_loss: 0.2385 - val_fmeasure: 0.9043\n",
      ">>> F1-score (6): 0.90488 Best (6): - 0.90973 (0.5 : -0.00485)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2102 - fmeasure: 0.9168 - val_loss: 0.2514 - val_fmeasure: 0.9001\n",
      ">>> F1-score (7): 0.90024 Best (7): + 0.90024 (0.5 : 0.00064)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2115 - fmeasure: 0.9173 - val_loss: 0.2630 - val_fmeasure: 0.8949\n",
      ">>> F1-score (8): 0.89521 Best (8): - 0.91146 (0.5 : -0.01625)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2076 - fmeasure: 0.9188 - val_loss: 0.2676 - val_fmeasure: 0.9047\n",
      ">>> F1-score (9): 0.9049 Best (9): + 0.9049 (0.5 : 0.00506)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2086 - fmeasure: 0.9178 - val_loss: 0.2573 - val_fmeasure: 0.9043\n",
      ">>> F1-score (10): 0.90448 Best (10): + 0.90448 (0.5 : 0.00337)\n",
      "\n",
      "F1-score for this epoch: 0.902923 ( 0.5 )-- Best F1-score::==> 0.904792 ( 0.5 )  (for epoch # 15 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 17/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2052 - fmeasure: 0.9200 - val_loss: 0.2360 - val_fmeasure: 0.9072\n",
      ">>> F1-score (1): 0.9074 Best (1): - 0.90756 (0.5 : -0.00016)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2045 - fmeasure: 0.9200 - val_loss: 0.2488 - val_fmeasure: 0.9072\n",
      ">>> F1-score (2): 0.90758 Best (2): + 0.90758 (0.5 : 0.00092)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2026 - fmeasure: 0.9202 - val_loss: 0.2756 - val_fmeasure: 0.8978\n",
      ">>> F1-score (3): 0.89819 Best (3): - 0.89968 (0.5 : -0.00149)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2024 - fmeasure: 0.9220 - val_loss: 0.2298 - val_fmeasure: 0.9139\n",
      ">>> F1-score (4): 0.91383 Best (4): - 0.91543 (0.5 : -0.0016)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2008 - fmeasure: 0.9219 - val_loss: 0.2613 - val_fmeasure: 0.9011\n",
      ">>> F1-score (5): 0.90157 Best (5): - 0.90296 (0.5 : -0.00139)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2055 - fmeasure: 0.9190 - val_loss: 0.2347 - val_fmeasure: 0.9121\n",
      ">>> F1-score (6): 0.9128 Best (6): + 0.9128 (0.5 : 0.00307)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2040 - fmeasure: 0.9191 - val_loss: 0.2454 - val_fmeasure: 0.9010\n",
      ">>> F1-score (7): 0.90136 Best (7): + 0.90136 (0.5 : 0.00112)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2082 - fmeasure: 0.9169 - val_loss: 0.2547 - val_fmeasure: 0.9063\n",
      ">>> F1-score (8): 0.90697 Best (8): - 0.91146 (0.5 : -0.00449)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2004 - fmeasure: 0.9204 - val_loss: 0.2667 - val_fmeasure: 0.9024\n",
      ">>> F1-score (9): 0.90253 Best (9): - 0.9049 (0.5 : -0.00237)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.2031 - fmeasure: 0.9208 - val_loss: 0.2474 - val_fmeasure: 0.9041\n",
      ">>> F1-score (10): 0.90445 Best (10): - 0.90448 (0.5 : -3e-05)\n",
      "\n",
      "F1-score for this epoch: 0.905668 ( 0.5 )-- Best F1-score::==> 0.905668 ( 0.5 )  (for epoch # 17 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 18/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.1979 - fmeasure: 0.9234 - val_loss: 0.2447 - val_fmeasure: 0.9067\n",
      ">>> F1-score (1): 0.90711 Best (1): - 0.90756 (0.5 : -0.00045)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.1973 - fmeasure: 0.9225 - val_loss: 0.2671 - val_fmeasure: 0.9052\n",
      ">>> F1-score (2): 0.90546 Best (2): - 0.90758 (0.5 : -0.00212)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 4s - loss: 0.1961 - fmeasure: 0.9244 - val_loss: 0.2785 - val_fmeasure: 0.9009\n",
      ">>> F1-score (3): 0.90109 Best (3): + 0.90109 (0.5 : 0.00141)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1973 - fmeasure: 0.9224 - val_loss: 0.2273 - val_fmeasure: 0.9104\n",
      ">>> F1-score (4): 0.91076 Best (4): - 0.91543 (0.5 : -0.00467)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1955 - fmeasure: 0.9238 - val_loss: 0.2620 - val_fmeasure: 0.9011\n",
      ">>> F1-score (5): 0.90161 Best (5): - 0.90296 (0.5 : -0.00135)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1977 - fmeasure: 0.9225 - val_loss: 0.2406 - val_fmeasure: 0.9084\n",
      ">>> F1-score (6): 0.9092 Best (6): - 0.9128 (0.5 : -0.0036)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1982 - fmeasure: 0.9234 - val_loss: 0.2446 - val_fmeasure: 0.9028\n",
      ">>> F1-score (7): 0.90315 Best (7): + 0.90315 (0.5 : 0.00179)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1990 - fmeasure: 0.9217 - val_loss: 0.2397 - val_fmeasure: 0.9108\n",
      ">>> F1-score (8): 0.91134 Best (8): - 0.91146 (0.5 : -0.00012)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1960 - fmeasure: 0.9234 - val_loss: 0.2740 - val_fmeasure: 0.9026\n",
      ">>> F1-score (9): 0.90296 Best (9): - 0.9049 (0.5 : -0.00194)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1956 - fmeasure: 0.9230 - val_loss: 0.2505 - val_fmeasure: 0.9061\n",
      ">>> F1-score (10): 0.90616 Best (10): + 0.90616 (0.5 : 0.00168)\n",
      "\n",
      "F1-score for this epoch: 0.905884 ( 0.5 )-- Best F1-score::==> 0.905884 ( 0.5 )  (for epoch # 18 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 19/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1939 - fmeasure: 0.9244 - val_loss: 0.2317 - val_fmeasure: 0.9081\n",
      ">>> F1-score (1): 0.90849 Best (1): + 0.90849 (0.5 : 0.00093)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59322/59322 [==============================] - 3s - loss: 0.1921 - fmeasure: 0.9247 - val_loss: 0.2503 - val_fmeasure: 0.9082\n",
      ">>> F1-score (2): 0.90882 Best (2): + 0.90882 (0.5 : 0.00124)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1924 - fmeasure: 0.9236 - val_loss: 0.2682 - val_fmeasure: 0.9006\n",
      ">>> F1-score (3): 0.90107 Best (3): - 0.90109 (0.5 : -2e-05)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1909 - fmeasure: 0.9247 - val_loss: 0.2337 - val_fmeasure: 0.9107\n",
      ">>> F1-score (4): 0.9109 Best (4): - 0.91543 (0.5 : -0.00453)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1897 - fmeasure: 0.9268 - val_loss: 0.2659 - val_fmeasure: 0.9051\n",
      ">>> F1-score (5): 0.90524 Best (5): + 0.90524 (0.5 : 0.00228)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1933 - fmeasure: 0.9248 - val_loss: 0.2341 - val_fmeasure: 0.9114\n",
      ">>> F1-score (6): 0.91194 Best (6): - 0.9128 (0.5 : -0.00086)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1921 - fmeasure: 0.9254 - val_loss: 0.2490 - val_fmeasure: 0.9019\n",
      ">>> F1-score (7): 0.90219 Best (7): - 0.90315 (0.5 : -0.00096)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1937 - fmeasure: 0.9249 - val_loss: 0.2459 - val_fmeasure: 0.9087\n",
      ">>> F1-score (8): 0.90936 Best (8): - 0.91146 (0.5 : -0.0021)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1914 - fmeasure: 0.9248 - val_loss: 0.2681 - val_fmeasure: 0.9053\n",
      ">>> F1-score (9): 0.90564 Best (9): + 0.90564 (0.5 : 0.00074)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1937 - fmeasure: 0.9245 - val_loss: 0.2504 - val_fmeasure: 0.9010\n",
      ">>> F1-score (10): 0.90108 Best (10): - 0.90616 (0.5 : -0.00508)\n",
      "\n",
      "F1-score for this epoch: 0.906473 ( 0.5 )-- Best F1-score::==> 0.906473 ( 0.5 )  (for epoch # 19 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~ BP/CC/MF ~~~~~~~~~~~~~~ EPOCH 20/20 (Embedding dimention: 100) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1878 - fmeasure: 0.9268 - val_loss: 0.2380 - val_fmeasure: 0.9097\n",
      ">>> F1-score (1): 0.90998 Best (1): + 0.90998 (0.5 : 0.00149)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1852 - fmeasure: 0.9289 - val_loss: 0.2524 - val_fmeasure: 0.9065\n",
      ">>> F1-score (2): 0.90698 Best (2): - 0.90882 (0.5 : -0.00184)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1853 - fmeasure: 0.9286 - val_loss: 0.2806 - val_fmeasure: 0.9003\n",
      ">>> F1-score (3): 0.90085 Best (3): - 0.90109 (0.5 : -0.00024)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1842 - fmeasure: 0.9277 - val_loss: 0.2379 - val_fmeasure: 0.9110\n",
      ">>> F1-score (4): 0.91095 Best (4): - 0.91543 (0.5 : -0.00448)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1867 - fmeasure: 0.9276 - val_loss: 0.2625 - val_fmeasure: 0.9024\n",
      ">>> F1-score (5): 0.90309 Best (5): - 0.90524 (0.5 : -0.00215)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1860 - fmeasure: 0.9274 - val_loss: 0.2459 - val_fmeasure: 0.9125\n",
      ">>> F1-score (6): 0.91301 Best (6): + 0.91301 (0.5 : 0.00021)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1855 - fmeasure: 0.9285 - val_loss: 0.2443 - val_fmeasure: 0.9027\n",
      ">>> F1-score (7): 0.90321 Best (7): + 0.90321 (0.5 : 6e-05)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1907 - fmeasure: 0.9257 - val_loss: 0.2352 - val_fmeasure: 0.9151\n",
      ">>> F1-score (8): 0.91546 Best (8): + 0.91546 (0.5 : 0.004)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1838 - fmeasure: 0.9279 - val_loss: 0.2596 - val_fmeasure: 0.9057\n",
      ">>> F1-score (9): 0.90602 Best (9): + 0.90602 (0.5 : 0.00038)\n",
      "\n",
      "Train on 59322 samples, validate on 3295 samples\n",
      "Epoch 1/1\n",
      "59322/59322 [==============================] - 3s - loss: 0.1878 - fmeasure: 0.9282 - val_loss: 0.2464 - val_fmeasure: 0.9032\n",
      ">>> F1-score (10): 0.90336 Best (10): - 0.90616 (0.5 : -0.0028)\n",
      "\n",
      "F1-score for this epoch: 0.907291 ( 0.5 )-- Best F1-score::==> 0.907291 ( 0.5 )  (for epoch # 20 of 20 epochs)\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~ FINAL RESULT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "For embedding size '100' best number of epochs is '20' with F1-score of: 0.907291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RES = {}\n",
    "best_total_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 3)\n",
    "cor = {}\n",
    "\n",
    "best_epoch = 0\n",
    "\n",
    "def pred(A, treshold = 0.5):\n",
    "    B = []\n",
    "    for n in A:\n",
    "        if treshold < n:\n",
    "            B.append(1)\n",
    "        else:\n",
    "            B.append(0)\n",
    "    return B\n",
    "\n",
    "def run_my_model(model_index, seq):\n",
    "    X_train, y_train, X_test, y_test = input_data_maker(model_id=model_index, \n",
    "                                                        test_size=test_size, \n",
    "                                                        indices=indices, \n",
    "                                                        annotation_G1_dic_MC=annotation_G1_dic_MC, \n",
    "                                                        annotation_G2_dic_MC=annotation_G2_dic_MC, \n",
    "                                                        interaction_pr_list_MC=interaction_pr_list_MC, \n",
    "                                                        annotation_G1_dic_HT=annotation_G1_dic_HT,\n",
    "                                                        annotation_G2_dic_HT=annotation_G2_dic_HT,\n",
    "                                                        interaction_pr_list_HT=interaction_pr_list_HT,\n",
    "                                                        SUB_ONTOLOGY_work=SUB_ONTOLOGY_work,\n",
    "                                                        WITH_HIGH_THROUPUT=False)\n",
    "    model = models[model_index]\n",
    "    history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=1, validation_data=(X_test,y_test))\n",
    "    p =  model.predict(X_test)\n",
    "    for i in seq:\n",
    "        predictions = np.asarray(pred(p, i))\n",
    "        B[model_index][i] = np.round(f1_score(y_test, predictions, average='binary'), 5)\n",
    "    pr = max(B[model_index].iteritems(), key=operator.itemgetter(1))[1]\n",
    "    thresholds[model_index] = max(B[model_index].iteritems(), key=operator.itemgetter(1))[0]\n",
    "    st = ''\n",
    "    b = bests[model_index]\n",
    "    if bests[model_index] < pr: \n",
    "        bests[model_index] = pr\n",
    "        treshold = thresholds[model_index]\n",
    "        st = \"+ \" + str(bests[model_index])\n",
    "    else:\n",
    "        st = \"- \" + str(bests[model_index])\n",
    "    print \">>> F1-score (\" + str(model_index + 1) + \"):\", pr, \"Best (\" + str(model_index + 1) + \"):\", st, \"(\" + str(thresholds[model_index]) + \" : \" + str(np.round(pr - b, 5)) + \")\" + \"\\n\"\n",
    "\n",
    "def get_results(epoch_no):\n",
    "    for i in seq:\n",
    "        RES[i] = 0\n",
    "        for j in range(FOLD):\n",
    "            RES[i] += B[j][i]/FOLD\n",
    "    res = max(RES.iteritems(), key=operator.itemgetter(1))[1]\n",
    "    threshold_res = max(RES.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    cor[epoch_no + 1] = res\n",
    "    total_max = 0\n",
    "    for i, j in sorted(cor.items(), key=operator.itemgetter(1)):\n",
    "        if total_max < j:\n",
    "            total_max = j\n",
    "            best_epoch = i\n",
    "            threshold_best = threshold_res\n",
    "    \n",
    "    print \"F1-score for this epoch:\", res, \"(\", threshold_res, \")-- Best F1-score::==>\", str(total_max), \"(\", threshold_best, \")  (for epoch #\", str(best_epoch), \"of\", str(NB_EPOCH), \"epochs)\" + \"\\n\"\n",
    "\n",
    "def get_final_result():\n",
    "    final_max = 0\n",
    "    best_epoch = 0\n",
    "    for i, j in sorted(cor.items(), key=operator.itemgetter(1)):\n",
    "        if final_max < j:\n",
    "            final_max = j\n",
    "            best_epoch = i\n",
    "        \n",
    "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~ FINAL RESULT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\" + \"\\n\" \n",
    "    print \"For embedding size '\" + str(EMBEDDING_DIM) + \"' best number of epochs is '\" + str(i) + \"' with F1-score of: \" + str(final_max) +\"\\n\"\n",
    "    \n",
    "for e in range(NB_EPOCH):\n",
    "     \n",
    "    print \"~~~~~~~~~ \" + '/'.join(SUB_ONTOLOGY_work) +\" ~~~~~~~~~~~~~~ EPOCH \" + str(e + 1) + \"/\" + str(NB_EPOCH) + \" (Embedding dimention: \" + str(EMBEDDING_DIM) + \") ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\" \n",
    "    seq = [0.5]\n",
    "    if SEQ:\n",
    "        seq = np.arange(0.11, 0.9, 0.01)\n",
    "        \n",
    "    for index in range(0, len(models)):\n",
    "        run_my_model(index, seq)\n",
    "    \n",
    "    get_results(e)\n",
    "\n",
    "get_final_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model and the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model 1 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "Saving model 2 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "Saving model 3 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "Saving model 4 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "Saving model 5 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "Saving model 6 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "Saving model 7 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "Saving model 8 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "Saving model 9 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "Saving model 10 to disk ...\n",
      "The Model and its Weights Are Saved!!\n",
      "\n",
      "The Word Embeddings Are Saved!!\n"
     ]
    }
   ],
   "source": [
    "if SAVE_MODEL:\n",
    "    save_model(FOLD=FOLD, models=models)\n",
    "    \n",
    "if SAVE_EMBEDDINGS:\n",
    "    save_embeddings(FOLD=FOLD, \n",
    "                           embedding_layers=embedding_layers,\n",
    "                           word_indeces=word_indeces, \n",
    "                           SUB_ONTOLOGY_work=SUB_ONTOLOGY_work,\n",
    "                           embedding_save=embedding_save)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
